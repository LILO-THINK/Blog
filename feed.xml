<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://blog.lilothink.science/feed.xml" rel="self" type="application/atom+xml" /><link href="https://blog.lilothink.science/" rel="alternate" type="text/html" /><updated>2024-08-05T20:41:58+00:00</updated><id>https://blog.lilothink.science/feed.xml</id><title type="html">BLOG - LILO.THINK</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><entry><title type="html">From Junk to Funk, Making a Musical Junker Box with Sonic Pi and Vintage Phones</title><link href="https://blog.lilothink.science/from-junk-to-funk-making-a-musical-junker-box-with-sonic-pi-and-vintage-phones/" rel="alternate" type="text/html" title="From Junk to Funk, Making a Musical Junker Box with Sonic Pi and Vintage Phones" /><published>2024-08-01T00:00:00+00:00</published><updated>2024-08-01T00:00:00+00:00</updated><id>https://blog.lilothink.science/from-junk-to-funk-making-a-musical-junker-box-with-sonic-pi-and-vintage-phones</id><content type="html" xml:base="https://blog.lilothink.science/from-junk-to-funk-making-a-musical-junker-box-with-sonic-pi-and-vintage-phones/"><![CDATA[<h2 id="sonic-pi-an-introduction">Sonic Pi: An Introduction</h2>

<p>Sonic Pi is an open-source programming environment designed for creating live music performances. Developed by Dr. Sam Aaron at the University of Cambridge Computer Laboratory, it has been in the market since 2014. Sonic Pi is built on top of SuperCollider, a platform for audio synthesis and algorithmic composition. The main goal of Sonic Pi is to introduce coding to a broader audience, particularly children, by making programming engaging and accessible through music.</p>

<p>The software has gained significant traction in both educational and creative sectors. It is widely used in classrooms to teach the basics of programming and music composition, as well as by professional musicians and live coders who perform complex, real-time audio compositions. Sonic Pi’s intuitive interface and powerful capabilities make it an ideal tool for both beginners and experienced users.</p>

<h2 id="workshop-and-creative-reuse-of-vintage-phones">Workshop and Creative Reuse of Vintage Phones</h2>

<p><a href="https://mrfx.ch/kontakt/">Felix Bänteli</a>, an artist and musician with a penchant for vintage technology, has amassed a collection of classic landline phones. These devices, with their distinctive bakelite keypads and analog mechanisms, evoke a sense of nostalgia and craftsmanship. Felix’s dedication to repurposing old electronics aligns perfectly with the ethos of sustainability and creative reuse.</p>

<p>During a recent Sonic Pi workshop led by Felix, participants were introduced to the basics of live coding and electronic music performance. During the workshop, I had an idea, why not bridge the gap between the analog charm of vintage phones and the digital creativity enabled by Sonic Pi? The potential to create unique audio-visual experiences by integrating old technology with modern programming tools became a focal point of my session.</p>

<h2 id="possibilities-with-sonic-pi">Possibilities with Sonic Pi</h2>

<p>Sonic Pi offers a wide array of possibilities for users:</p>

<ol>
  <li>
    <p><strong>Live Coding Performances</strong>: Users can write and modify code in real-time to create dynamic music performances. This aspect of Sonic Pi is particularly popular in the live coding community, where musicians and programmers perform live shows.</p>
  </li>
  <li>
    <p><strong>Educational Tool</strong>: It serves as an excellent educational platform, introducing students to programming concepts through interactive and enjoyable lessons. Sonic Pi is used in schools worldwide to teach coding in a fun and engaging way.</p>
  </li>
  <li>
    <p><strong>Creative Exploration</strong>: Beyond its educational value, Sonic Pi is a powerful tool for creative expression. Artists and musicians can experiment with sound synthesis, rhythm, and composition, pushing the boundaries of conventional music production.</p>
  </li>
  <li>
    <p><strong>Community and Collaboration</strong>: Sonic Pi has a vibrant community of users who share their code, performances, and experiences. This collaborative spirit fosters continuous learning and innovation within the platform.</p>
  </li>
</ol>

<h2 id="bridging-the-gap-from-musical-concepts-to-sonic-pi-with-openai">Bridging the Gap: From Musical Concepts to Sonic Pi with OpenAI</h2>

<p>As someone without a formal musical background, I found myself grappling with the fundamental concepts of music during the Sonic Pi workshop. I think understanding these concepts is crucial for translating musical thoughts into programmable code. It felt akin to building with LEGO without knowing the basic pieces—challenging and somewhat daunting.</p>

<p>In an attempt to overcome this, I turned to ChatGPT for assistance. By requesting the code for specific songs, like the theme from Inspector Gadget, I began to see how musical elements are structured within Sonic Pi. This approach allowed me to dissect and modify the provided code, gradually building my understanding of musical composition in a programmable context.</p>

<p>However, the process of switching between the ChatGPT interface and Sonic Pi was cumbersome. This sparked an idea: what if I could directly request and implement code in Sonic Pi using voice commands? To achieve this, I leveraged the OpenAI API for speech transcription, coupled with OSC (Open Sound Control) to establish a direct connection between my voice and Sonic Pi.</p>

<p>By integrating these technologies, I created a seamless workflow where I could verbally request a song, receive the corresponding Sonic Pi code, and immediately start experimenting with it. This direct link not only streamlined my creative process but also made it more intuitive and accessible, even for someone without a deep musical background.</p>

<p>This innovative approach highlights the potential of combining modern AI capabilities with creative coding platforms, opening new doors for musical exploration and education.</p>

<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/200845412@N02/53896713791/in/album-72177720319282088/" title="Untitled"><img src="https://live.staticflickr.com/31337/53896713791_96d1ffc459_z.jpg" width="360" height="640" alt="Untitled" /></a><script async="" src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<h2 id="creating-a-musical-junker-box-connecting-vintage-phones-with-sonic-pi-via-openai">Creating a Musical Junker Box: Connecting Vintage Phones with Sonic Pi via OpenAI</h2>

<p>So, off I went to delve into Python scripts. Python, with its voice recognition capabilities, was my tool of choice for creating a voice-controlled prompt. I set up a system where I could verbally request a song. This voice prompt would be processed by the OpenAI API, which in turn generated the corresponding Sonic Pi code for the requested song.</p>

<p>Once the code was generated by OpenAI, it was sent back in the format Sonic Pi expects, and then transmitted via OSC (Open Sound Control). OSC is a protocol used in music technology for networking sound synthesis and performance. It allows for the transmission of music-related data over a network, enabling various devices and software to communicate seamlessly. In my setup, Sonic Pi simply needed to be open and listening on the correct port to receive and play the generated music.</p>

<p>For the final touch, I repurposed an old landline phone, utilizing its microphone and speaker. I connected it through an audio interface, specifically the UR22, which <a href="https://www.linkedin.com/in/claude-treptow-a0bb1214b?utm_source=share&amp;utm_campaign=share_via&amp;utm_content=profile&amp;utm_medium=android_app">Claude Treptow</a> one of the artists at the Summer Camp provided. This interface allowed me to link the vintage phone components to my computer, bridging the analog-digital divide.</p>

<p>The result was a whimsical musical junker box. I could pick up the phone handle, request a song—say, “Happy Birthday” for Miranda’s birthday—and hear the melody played back through the phone’s speaker. This entire process was driven by my voice command, interpreted by OpenAI, and executed in Sonic Pi.</p>

<p>This project exemplifies the joy of experimentation. Even without a deep understanding of music theory, I was able to leverage modern tools to explore and create. By combining vintage technology with cutting-edge software, I turned a simple workshop exercise into an innovative and fun musical experience.</p>

<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/200845412@N02/albums/72177720319282088" title="2024 07 Vintage Phone To Sonic Pi"><img src="https://live.staticflickr.com/31337/53896713791_96d1ffc459.jpg" width="640" height="480" alt="2024 07 Vintage Phone To Sonic Pi" /></a><script async="" src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<h2 id="tutorialcodes">Tutorial/Codes</h2>
<h3 id="configuration-sonic-pi">Configuration Sonic Pi</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>define :execute_commands do |commands|
  commands.each do |command|
    eval command
  end
end

live_loop :foo do
  use_real_time
  commands = sync "/osc*/trigger"
  execute_commands(commands)
  synth :piano
end
</code></pre></div></div>

<h3 id="script-python---voice-recognition-and-openai">Script Python - voice recognition and OpenAI</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">speech_recognition</span> <span class="k">as</span> <span class="n">sr</span>
<span class="kn">import</span> <span class="n">openai</span>
<span class="kn">from</span> <span class="n">pythonosc</span> <span class="kn">import</span> <span class="n">udp_client</span>

<span class="c1"># Set your OpenAI API key
</span><span class="n">openai</span><span class="p">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="sh">'</span><span class="s">YOUR-OPENAI-KEY</span><span class="sh">'</span>

<span class="c1"># Set up OSC client
</span><span class="n">client</span> <span class="o">=</span> <span class="n">udp_client</span><span class="p">.</span><span class="nc">SimpleUDPClient</span><span class="p">(</span><span class="sh">"</span><span class="s">127.0.0.1</span><span class="sh">"</span><span class="p">,</span> <span class="mi">4560</span><span class="p">)</span> <span class="c1"># Ensure this matches your Sonic Pi setup
</span>
<span class="k">def</span> <span class="nf">get_voice_input</span><span class="p">():</span>
    <span class="n">recognizer</span> <span class="o">=</span> <span class="n">sr</span><span class="p">.</span><span class="nc">Recognizer</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">sr</span><span class="p">.</span><span class="nc">Microphone</span><span class="p">()</span> <span class="k">as</span> <span class="n">source</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Listening for your musical prompt...</span><span class="sh">"</span><span class="p">)</span>
        <span class="n">audio</span> <span class="o">=</span> <span class="n">recognizer</span><span class="p">.</span><span class="nf">listen</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="n">recognizer</span><span class="p">.</span><span class="nf">recognize_google</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">You said: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prompt</span>
    <span class="k">except</span> <span class="n">sr</span><span class="p">.</span><span class="n">UnknownValueError</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Sorry, I did not understand that.</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">None</span>
    <span class="k">except</span> <span class="n">sr</span><span class="p">.</span><span class="n">RequestError</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Sorry, there</span><span class="sh">'</span><span class="s">s an issue with the voice recognition service.</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">None</span>

<span class="k">def</span> <span class="nf">get_music_code</span><span class="p">(</span><span class="n">prompt</span><span class="p">):</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">openai</span><span class="p">.</span><span class="n">ChatCompletion</span><span class="p">.</span><span class="nf">create</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="sh">"</span><span class="s">gpt-3.5-turbo</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
            <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">You are a helpful assistant.</span><span class="sh">"</span><span class="p">},</span>
            <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sa">f</span><span class="sh">"</span><span class="s">Generate Sonic Pi (just the sequence code, NONE other word NOT THE WORD RUBY) code (without the definition of bpm or synth) for the following musical request: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="sh">"</span><span class="p">}</span>
        <span class="p">],</span>
        <span class="n">max_tokens</span><span class="o">=</span><span class="mi">150</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">response</span><span class="p">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">message</span><span class="p">[</span><span class="sh">'</span><span class="s">content</span><span class="sh">'</span><span class="p">].</span><span class="nf">strip</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">send_code_to_sonic_pi</span><span class="p">(</span><span class="n">code</span><span class="p">):</span>
    <span class="n">client</span><span class="p">.</span><span class="nf">send_message</span><span class="p">(</span><span class="sh">"</span><span class="s">/trigger</span><span class="sh">"</span><span class="p">,</span> <span class="n">code</span><span class="p">)</span>
  
<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="nf">get_voice_input</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">prompt</span><span class="p">:</span>
        <span class="n">code</span> <span class="o">=</span> <span class="nf">get_music_code</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Generated Sonic Pi code:</span><span class="se">\n</span><span class="si">{</span><span class="n">code</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="nf">send_code_to_sonic_pi</span><span class="p">(</span><span class="n">code</span><span class="p">)</span>

</code></pre></div></div>]]></content><author><name>lina</name></author><category term="documentation" /><category term="sound" /><category term="AI projects" /><category term="homemade2024" /><category term="sonic-pi" /><category term="openai" /><category term="python" /><summary type="html"><![CDATA[Sonic Pi: An Introduction]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://live.staticflickr.com/65535/53896955078_978ca5f438_z.jpg" /><media:content medium="image" url="https://live.staticflickr.com/65535/53896955078_978ca5f438_z.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How a Summer Camp Sparked My Curiosity About the RP2040 and How It Can Spark Yours Too!</title><link href="https://blog.lilothink.science/how-a-summer-camp-sparked-my-curiosity-about-the-rp2040-and-how-it-can-spark-yours-too/" rel="alternate" type="text/html" title="How a Summer Camp Sparked My Curiosity About the RP2040 and How It Can Spark Yours Too!" /><published>2024-07-31T00:00:00+00:00</published><updated>2024-07-31T00:00:00+00:00</updated><id>https://blog.lilothink.science/how-a-summer-camp-sparked-my-curiosity-about-the-rp2040-and-how-it-can-spark-yours-too</id><content type="html" xml:base="https://blog.lilothink.science/how-a-summer-camp-sparked-my-curiosity-about-the-rp2040-and-how-it-can-spark-yours-too/"><![CDATA[<p>I found myself immersed in my own tinkering at a shared table during a vibrant summer camp. It was then that Tormod approached me with an intriguing piece of hardware: the RP2040 development board.</p>

<p>The RP2040-GEEK Development Board sits intriguingly between the well-known Raspberry Pi and Arduino platforms. While the Raspberry Pi offers a full-fledged computing experience with its operating system and Arduino provides a straightforward, microcontroller-centric approach, the RP2040 seems to blend elements of both worlds.</p>

<p>The key lies in its versatility and convenience. For projects requiring a simple user interface without the overhead of a full operating system, the RP2040 strikes a perfect balance. It’s powerful enough to handle complex tasks, yet straightforward for quick prototyping. This makes it an excellent choice for applications where a small display is beneficial, such as portable devices, educational tools, and compact IoT projects.</p>

<p><img src="https://circuitpython.org/assets/images/boards/large/waveshare_rp2040_geek.jpg" /></p>

<h3 id="possibilities">Possibilities</h3>

<p><strong>Handheld Devices:</strong></p>
<ul>
  <li><strong>Portable Games:</strong> Create simple handheld games using the built-in color LCD for graphics and buttons for control.</li>
  <li><strong>Digital Notepad:</strong> Develop a small digital notepad that allows users to write and save notes using a simple interface.</li>
</ul>

<p><strong>User Interfaces:</strong></p>
<ul>
  <li><strong>Custom GUIs:</strong> Design custom graphical user interfaces for other projects, such as control panels for home automation or industrial applications.</li>
  <li><strong>Status Monitors:</strong> Implement a device that shows real-time data or status updates from sensors or online services.</li>
</ul>

<p><strong>Educational Tools:</strong></p>
<ul>
  <li><strong>Learning Kits:</strong> Build educational kits for learning programming and electronics, leveraging the LCD to display information, instructions, or feedback.</li>
  <li><strong>Interactive Displays:</strong> Create interactive learning tools for classrooms, where students can interact with the display and buttons.</li>
</ul>

<p><strong>Wearable Tech:</strong></p>
<ul>
  <li><strong>Smart Badges:</strong> Design smart badges for events or conferences that display attendee information, schedules, or messages.</li>
  <li><strong>Fitness Trackers:</strong> Develop basic fitness trackers that display steps, heart rate, or other health metrics.</li>
</ul>

<p><strong>IoT Devices:</strong></p>
<ul>
  <li><strong>Weather Stations:</strong> Implement a small weather station that shows temperature, humidity, and other environmental data on the LCD.</li>
  <li><strong>Home Automation:</strong> Create control panels for home automation systems, allowing users to manage lights, temperature, and security from a single device.</li>
</ul>

<p><strong>Art and Creativity:</strong></p>
<ul>
  <li><strong>Mini Art Displays:</strong> Design mini art displays or digital photo frames that cycle through images or animations.</li>
  <li><strong>Interactive Installations:</strong> Build interactive art installations that respond to user inputs and display dynamic graphics.</li>
</ul>

<p><strong>Prototyping and Testing:</strong></p>
<ul>
  <li><strong>Sensor Data Display:</strong> Use the board to display real-time data from various sensors for testing and prototyping purposes.</li>
  <li><strong>Control Interfaces:</strong> Develop interfaces to control other devices or systems, using the display to show status and options.</li>
</ul>

<h3 id="technical-aspects">Technical Aspects</h3>

<p>The RP2040 is impressively small and utilizes JST connectors for sensor connections, such as I2C for external communication. The integrated display and USB port are standout features that caught my attention. The display provides quick feedback when connected to sensors, and the USB port allows easy power connection via a power bank.</p>

<p>As I started exploring, I was impressed by its simplicity. Plugging it into my Mac, I was able to access it by directly loading Python scripts onto its root directory. Without a microSD card, I used the board’s built-in memory, which, while limited, was sufficient for my initial experiments. The RP2040 runs <a href="https://circuitpython.org/board/waveshare_rp2040_geek/">CircuitPython firmware</a>, which allowed me to install a few libraries, like Adafruit Shapes, to create basic animations.</p>

<p>For my test, I created an animation of the Swiss flag. This hands-on experience highlighted the board’s potential for quick prototyping and creative projects.</p>

<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/200845412@N02/53892961357/in/dateposted-public/" title="Untitled"><img src="https://live.staticflickr.com/31337/53892961357_8640d918d6_z.jpg" width="360" height="640" alt="Untitled" /></a><script async="" src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p>Tormod also showcased other possibilities with the RP2040. Notably, there is a circular version of the integrated display, which can be used to create interfaces resembling watches or brooches.</p>

<h3 id="the-power-of-community">The Power of Community</h3>

<p>What I want to emphasize and celebrate is the collaborative spirit fostered in gatherings like this summer camp. The participants are not only curious but also generous. Sitting there, I might never have discovered this board, or at least not so soon. Yet, because someone was involved and interested, I had the chance to learn about it. These encounters build a sense of community, highlighting the beautiful aspect of the information economy: sharing knowledge enriches everyone involved. This generosity and exchange of information are inspiring and invaluable for learning and innovation.</p>

<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/200845412@N02/albums/72177720319257368" title="2024 07 RP2040 Swiss Flag"><img src="https://live.staticflickr.com/65535/53894213894_9031ddc305.jpg" width="640" height="480" alt="2024 07 RP2040 Swiss Flag" /></a><script async="" src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<h2 id="tutorial-creating-a-small-animation-with-rp2040-geek-by-waveshare-and-adafruit-shapes-library">Tutorial: Creating a Small Animation with RP2040-GEEK by Waveshare and Adafruit Shapes Library</h2>

<p>In this tutorial, we’ll walk you through the steps to create a small animation on the RP2040-GEEK development board by Waveshare using the Adafruit Shapes library and CircuitPython 9.</p>

<h4 id="what-youll-need"><strong>What You’ll Need:</strong></h4>
<ul>
  <li>RP2040-GEEK Development Board by Waveshare</li>
  <li>USB cable</li>
  <li>Computer (Mac, Windows, or Linux)</li>
  <li>CircuitPython firmware</li>
  <li>Adafruit Shapes library</li>
</ul>

<h4 id="step-1-set-up-circuitpython-on-rp2040-geek"><strong>Step 1: Set Up CircuitPython on RP2040-GEEK</strong></h4>
<ol>
  <li><strong>Download CircuitPython Firmware:</strong>
    <ul>
      <li>Visit the <a href="https://circuitpython.org/board/waveshare_rp2040_geek/">CircuitPython downloads page</a>.</li>
      <li>Download the latest firmware for the RP2040-GEEK.</li>
    </ul>
  </li>
  <li><strong>Install CircuitPython:</strong>
    <ul>
      <li>Connect your RP2040-GEEK to your computer using the USB cable.</li>
      <li>Double-click the reset button on the board to put it into bootloader mode. The board should appear as a USB drive named <code class="language-plaintext highlighter-rouge">RPI-RP2</code>.</li>
      <li>Drag and drop the downloaded <code class="language-plaintext highlighter-rouge">.uf2</code> file onto the <code class="language-plaintext highlighter-rouge">RPI-RP2</code> drive. The board will reboot and appear as a new USB drive named <code class="language-plaintext highlighter-rouge">CIRCUITPY</code>.</li>
    </ul>
  </li>
</ol>

<h4 id="step-2-install-required-libraries"><strong>Step 2: Install Required Libraries</strong></h4>

<ol>
  <li><strong>Download Adafruit CircuitPython Library Bundle:</strong>
    <ul>
      <li>Go to the <a href="https://github.com/adafruit/Adafruit_CircuitPython_Bundle/releases/tag/20240730">Adafruit CircuitPython Library Bundle</a>.</li>
      <li>Download the latest bundle as a <code class="language-plaintext highlighter-rouge">.zip</code> file.</li>
    </ul>
  </li>
  <li><strong>Copy Libraries to CIRCUITPY:</strong>
    <ul>
      <li>Extract the downloaded <code class="language-plaintext highlighter-rouge">.zip</code> file.</li>
      <li>Copy the following libraries from the extracted bundle to the <code class="language-plaintext highlighter-rouge">lib</code> folder on the <code class="language-plaintext highlighter-rouge">CIRCUITPY</code> drive:
        <ul>
          <li><code class="language-plaintext highlighter-rouge">adafruit_display_shapes</code></li>
          <li><code class="language-plaintext highlighter-rouge">adafruit_displayio_ssd1306</code> (if using an OLED display)</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h4 id="step-3-write-your-python-script"><strong>Step 3: Write Your Python Script</strong></h4>

<ol>
  <li><strong>Create a New Python File:</strong>
    <ul>
      <li>On the <code class="language-plaintext highlighter-rouge">CIRCUITPY</code> drive, create a new file named <code class="language-plaintext highlighter-rouge">code.py</code>.</li>
    </ul>
  </li>
  <li><strong>Write the Animation Code:</strong></li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">time</span>
<span class="kn">import</span> <span class="n">gc</span>
<span class="kn">import</span> <span class="n">board</span>
<span class="kn">import</span> <span class="n">displayio</span>
<span class="kn">from</span> <span class="n">adafruit_display_shapes.rect</span> <span class="kn">import</span> <span class="n">Rect</span>

<span class="c1"># use built in display (MagTag, PyPortal, PyGamer, PyBadge, CLUE, etc.)
# see guide for setting up external displays (TFT / OLED breakouts, RGB matrices, etc.)
# https://learn.adafruit.com/circuitpython-display-support-using-displayio/display-and-display-bus
</span><span class="n">display</span> <span class="o">=</span> <span class="n">board</span><span class="p">.</span><span class="n">DISPLAY</span>

<span class="c1"># Make the display context
</span><span class="n">main_group</span> <span class="o">=</span> <span class="n">displayio</span><span class="p">.</span><span class="nc">Group</span><span class="p">()</span>

<span class="c1"># Make a red background color fill
</span><span class="n">color_bitmap</span> <span class="o">=</span> <span class="n">displayio</span><span class="p">.</span><span class="nc">Bitmap</span><span class="p">(</span><span class="n">display</span><span class="p">.</span><span class="n">width</span><span class="p">,</span> <span class="n">display</span><span class="p">.</span><span class="n">height</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">color_palette</span> <span class="o">=</span> <span class="n">displayio</span><span class="p">.</span><span class="nc">Palette</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">color_palette</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mh">0xFF0000</span>
<span class="n">bg_sprite</span> <span class="o">=</span> <span class="n">displayio</span><span class="p">.</span><span class="nc">TileGrid</span><span class="p">(</span><span class="n">color_bitmap</span><span class="p">,</span> <span class="n">pixel_shader</span><span class="o">=</span><span class="n">color_palette</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">main_group</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">bg_sprite</span><span class="p">)</span>

<span class="c1"># Setting up the cross starting position
</span><span class="n">posx</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">posy</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1"># Define cross characteristics
</span><span class="n">cross_size</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">cross_color</span> <span class="o">=</span> <span class="mh">0xFFFFFF</span>

<span class="c1"># Create horizontal and vertical rectangles to form the cross
</span><span class="n">horizontal_rect</span> <span class="o">=</span> <span class="nc">Rect</span><span class="p">(</span><span class="n">posx</span> <span class="o">-</span> <span class="n">cross_size</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">posy</span> <span class="o">-</span> <span class="n">cross_size</span><span class="o">//</span><span class="mi">8</span><span class="p">,</span> <span class="n">cross_size</span><span class="p">,</span> <span class="n">cross_size</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="n">cross_color</span><span class="p">)</span>
<span class="n">vertical_rect</span> <span class="o">=</span> <span class="nc">Rect</span><span class="p">(</span><span class="n">posx</span> <span class="o">-</span> <span class="n">cross_size</span><span class="o">//</span><span class="mi">8</span><span class="p">,</span> <span class="n">posy</span> <span class="o">-</span> <span class="n">cross_size</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">cross_size</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">cross_size</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="n">cross_color</span><span class="p">)</span>

<span class="n">main_group</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">horizontal_rect</span><span class="p">)</span>
<span class="n">main_group</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">vertical_rect</span><span class="p">)</span>

<span class="c1"># Define cross Animation Steps
</span><span class="n">delta_x</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">delta_y</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Showing the items on the screen
</span><span class="n">display</span><span class="p">.</span><span class="n">root_group</span> <span class="o">=</span> <span class="n">main_group</span>

<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">vertical_rect</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">cross_size</span><span class="o">//</span><span class="mi">2</span> <span class="o">&gt;=</span> <span class="n">display</span><span class="p">.</span><span class="n">height</span><span class="p">:</span>
        <span class="n">delta_y</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
    <span class="k">if</span> <span class="n">horizontal_rect</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">cross_size</span><span class="o">//</span><span class="mi">2</span> <span class="o">&gt;=</span> <span class="n">display</span><span class="p">.</span><span class="n">width</span><span class="p">:</span>
        <span class="n">delta_x</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
    <span class="k">if</span> <span class="n">horizontal_rect</span><span class="p">.</span><span class="n">x</span> <span class="o">-</span> <span class="n">cross_size</span><span class="o">//</span><span class="mi">2</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">delta_x</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">if</span> <span class="n">vertical_rect</span><span class="p">.</span><span class="n">y</span> <span class="o">-</span> <span class="n">cross_size</span><span class="o">//</span><span class="mi">2</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">delta_y</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="n">horizontal_rect</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">horizontal_rect</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">delta_x</span>
    <span class="n">vertical_rect</span><span class="p">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">vertical_rect</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">delta_x</span>
    <span class="n">horizontal_rect</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">horizontal_rect</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">delta_y</span>
    <span class="n">vertical_rect</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">vertical_rect</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">delta_y</span>

    <span class="n">time</span><span class="p">.</span><span class="nf">sleep</span><span class="p">(</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="n">gc</span><span class="p">.</span><span class="nf">collect</span><span class="p">()</span>

</code></pre></div></div>

<h4 id="step-4-run-your-script"><strong>Step 4: Run Your Script</strong></h4>

<ol>
  <li><strong>Save the Script:</strong>
    <ul>
      <li>Save the <code class="language-plaintext highlighter-rouge">code.py</code> file on the <code class="language-plaintext highlighter-rouge">CIRCUITPY</code> drive.</li>
      <li>The RP2040-GEEK board will automatically run the script, displaying the animation on the integrated display.</li>
    </ul>
  </li>
  <li><strong>Observe the Animation:</strong>
    <ul>
      <li>You should see a red background with a white cross around the screen.</li>
    </ul>
  </li>
</ol>]]></content><author><name>lina</name></author><category term="documentation" /><category term="creative process" /><category term="hardware" /><category term="homemade2024" /><category term="rp2040" /><category term="python" /><summary type="html"><![CDATA[I found myself immersed in my own tinkering at a shared table during a vibrant summer camp. It was then that Tormod approached me with an intriguing piece of hardware: the RP2040 development board.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://live.staticflickr.com/65535/53894228919_96a13c8a65_z.jpg" /><media:content medium="image" url="https://live.staticflickr.com/65535/53894228919_96a13c8a65_z.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Can Simple Materials Unleash the Power of Vortex Energy?</title><link href="https://blog.lilothink.science/can-simple-materials-unleash-the-power-of-vortex-energy/" rel="alternate" type="text/html" title="Can Simple Materials Unleash the Power of Vortex Energy?" /><published>2024-07-30T00:00:00+00:00</published><updated>2024-07-30T00:00:00+00:00</updated><id>https://blog.lilothink.science/can-simple-materials-unleash-the-power-of-vortex-energy</id><content type="html" xml:base="https://blog.lilothink.science/can-simple-materials-unleash-the-power-of-vortex-energy/"><![CDATA[<h2 id="motivation">Motivation</h2>

<p>During breakfast this morning at the Homemade summer camp in 2004, I had the pleasure of meeting <a href="https://mirandamoss.com/">Miranda Moss</a>. As we enjoyed our coffee, she shared details about her intriguing projects focused on “biodiversity of energy.” Miranda has already designed several PCBs (Printed Circuit Boards) aimed at harnessing solar energy. Currently, she is captivated by the potential of gravity batteries, which leverage mechanical principles to store and release energy.</p>

<p>Our conversation took an even more interesting turn when Fadri Pestalozzi (aka my husband) joined us. He introduced us to the concept of the Water Vortex Power Plant, sparking a lively discussion about sustainable energy solutions.</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Gravitationswasserwirbelkraftwerk_mit_Zotl%C3%B6terer_Turbine_in_Obergrafendorf_%28AUSTRIA%29.jpg/1920px-Gravitationswasserwirbelkraftwerk_mit_Zotl%C3%B6terer_Turbine_in_Obergrafendorf_%28AUSTRIA%29.jpg" /></p>

<p><em>A gravitation water vortex plant in Austria - wikipedia source</em></p>

<h2 id="water-vortex-power-plant-an-overview">Water Vortex Power Plant: An Overview</h2>

<p>The Water Vortex Power Plant is an innovative approach to generating electricity by harnessing the natural motion of water. This technology utilizes the kinetic energy produced by a controlled water vortex to drive turbines and generate power. The history of this concept dates back to ancient techniques of water management and milling, but modern applications have optimized these principles for efficient energy production.</p>

<p>The primary purpose of a Water Vortex Power Plant is to provide a sustainable and environmentally friendly method of generating electricity. By utilizing the <strong>natural flow of water</strong>, it minimizes the ecological footprint compared to traditional hydroelectric power plants. This technology is particularly advantageous in areas with limited resources, as it can be implemented with relatively <strong>simple infrastructure and without the need for large-scale dams or reservoirs</strong>.</p>

<h2 id="hands-on-prototyping-the-initial-exploration">Hands-On Prototyping: The Initial Exploration</h2>

<p>For our hands-on project, we started with the materials we had available, focusing initially on a NEMA 17 motor that I had brought along in my bag. To create a makeshift turbine, we designed a structure with blades to fit inside a plastic cup. We drilled holes into the cup and threaded a tube through it, using what was available to us in terms of tinkering materials. This included creative learning supplies such as scraps and items typically found at home.</p>

<p>Our first prototype utilized Lego pieces to build the motor’s structure atop the cup, which was intended to act as our turbine. We also incorporated wooden blocks from a stacking game and small hoses I had on hand, creating a rudimentary yet functional setup using tinkering techniques. This approach allowed us to rapidly iterate and adjust our design with readily available components.</p>

<p>Upon testing this initial prototype, we discovered a significant issue: the NEMA 17 motor required more torque to rotate the blades than our setup could provide. This realization prompted us to reconsider our design and the materials used. We concluded that for the next iteration, we would need a motor that could turn the shaft more easily and efficiently.</p>

<p>This process underscored the importance of prototyping and iterative design. By working hands-on with what we had, we were able to quickly identify limitations and gather insights for improving our approach. The collaborative environment and resourceful use of materials turned our challenges into learning opportunities, driving us toward a more viable solution for our energy generation project.</p>

<p><img src="https://live.staticflickr.com/65535/53891867094_d43b5a57f3_z.jpg" /></p>

<h2 id="hands-on-prototyping-the-second-exploration">Hands-On Prototyping: The Second Exploration</h2>

<p>For our second prototype, Miranda provided a motor with less friction on its shaft, which she had salvaged from a piece of discarded electronic equipment. This motor had a pulley firmly attached to its shaft, and we decided to utilize the pulley as it was rather than removing it.</p>

<p>One of the most interesting materials we used in this process was a wine cork. Cork, being easy to carve, allowed us to fit it onto the motor’s pulley securely. To ensure the cork stayed in place, we used hot glue to fix it firmly to the pulley.</p>

<p>We also took advantage of cork’s resilience to secure the new blades for our turbine. Unlike the first prototype, which used wooden blocks, we opted for PET bottles. The PET bottle served a dual purpose: it formed both the water tank to generate the vortex and the blades that the water would spin to drive the motor.</p>

<p>Additionally, the motor structure required an upgrade. Instead of using Lego pieces as in the first prototype, we employed metal L-brackets typically used in furniture assembly. These 90-degree angle brackets provided a more robust and stable framework for the motor.</p>

<p>This second prototype marked a significant improvement over the first, we managed to turn on the red LED! Through this iterative process, we learned the importance of material selection and adaptability. Each prototype taught us valuable lessons about the limitations and potential of our chosen components. This hands-on, collaborative tinkering approach allowed us to innovate creatively and make significant progress toward our goal of building a functional water vortex power plant.</p>

<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/200845412@N02/53892112815/in/album-72177720319236248/" title="Untitled"><img src="https://live.staticflickr.com/31337/53892112815_55c8961751_z.jpg" width="360" height="640" alt="Untitled" /></a><script async="" src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<h2 id="conclusion-lessons-learned-from-the-prototyping-process">Conclusion: Lessons Learned from the Prototyping Process</h2>

<p>Throughout this hands-on prototyping journey, we learned that pursuing an idea with limited materials and resources is indeed possible. Even without access to advanced tools like 3D printers, laser cutters, or other materials typically found in our usual environment, we relied on the creativity and ingenuity of our team. The flexibility of materials and the collaborative effort allowed us to mentally stretch and innovate in the design of physical products.</p>

<p>Our experience with the quick, “dirty” prototyping process highlighted its primary advantage: it enables rapid proof-of-concept creation within a single day. By utilizing available materials such as electric components, hot glue, wood pieces, and metal structures, we could swiftly test our ideas. However, we also recognized the limitations of such prototypes. They serve as an initial testbed, helping us understand the design’s impact on efficiency and revealing areas for improvement.</p>

<p>One potential enhancement we identified is incorporating a gearbox to optimize the motor’s performance. Our goal was to generate enough energy to light a red LED, but the water vortex’s drag required higher speed and torque than our current setup could provide. A more refined vortex motor design, possibly created through 3D printing, could significantly improve efficiency.</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/0/00/Wasserwirbelkraftwerk.jpg" /></p>

<p><em>from <a href="https://commons.wikimedia.org/wiki/File:Wasserwirbelkraftwerk.jpg">wikimedia commons</a></em></p>

<p>Additionally, the unique motor from discarded electronic posed documentation challenges for reproducibility. Despite this, the principles of collaborative and iterative design remained evident. While we could have spent more time on detailed calculations and designs, our one-day efforts demonstrated the power of hands-on experimentation.</p>

<p>Reflecting on the process, we see potential applications beyond this project. For instance, my mother’s rural small property with flowing water could benefit from this concept. Alternatively, the setup could serve as an intriguing artistic installation. Ultimately, this prototyping experience underscored the value of resourcefulness and teamwork in driving innovation and exploring new possibilities.</p>

<p>Our breakfast discussion highlights the essence of the summer camp: a collaborative, immersive environment where resourcefulness and shared knowledge drive innovation. Despite the limitations in materials and machinery, <strong>the camp’s focus on collective imagination and idea exchange fuels our creativity</strong>. It is within these constraints that we find the clarity and determination to push boundaries and explore new frontiers in sustainable technology.</p>

<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/200845412@N02/albums/72177720319236248" title="2024 07 Water Vortex Power"><img src="https://live.staticflickr.com/65535/53890771677_b380f88c11_z.jpg" width="640" height="480" alt="2024 07 Water Vortex Power" /></a><script async="" src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p><em>More pictures and videos on Flickr Gallery</em></p>]]></content><author><name>lina</name></author><category term="documentation" /><category term="energy" /><category term="kinetic" /><category term="homemade2024" /><category term="motor" /><summary type="html"><![CDATA[Motivation]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://live.staticflickr.com/65535/53891950555_5c2656ef93_z.jpg" /><media:content medium="image" url="https://live.staticflickr.com/65535/53891950555_5c2656ef93_z.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Tinkering for 2 Hours with a Canon EOS 40D That’s Older Than My Daughter</title><link href="https://blog.lilothink.science/tinkering-for-2-hours-with-a-canon-eos-40d-that-s-older-than-my-daughter/" rel="alternate" type="text/html" title="Tinkering for 2 Hours with a Canon EOS 40D That’s Older Than My Daughter" /><published>2024-07-29T00:00:00+00:00</published><updated>2024-07-29T00:00:00+00:00</updated><id>https://blog.lilothink.science/tinkering-for-2-hours-with-a-canon-eos-40d-that-s-older-than-my-daughter</id><content type="html" xml:base="https://blog.lilothink.science/tinkering-for-2-hours-with-a-canon-eos-40d-that-s-older-than-my-daughter/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Yesterday, I met <a href="https://mrfx.ch/kontakt/">Felix Bänteli</a>, an artist who has a passion for collecting vintage equipment. Among his treasures was a 2007 Canon EOS 40D, a groundbreaking camera at its time. As we chatted, we remarked on how images on social media, especially on platforms like Instagram, all share the same polished aesthetic. These images, with their perfect lighting and impeccable composition, for me often blur the line between reality and AI-generated content.</p>

<p>This conversation sparked an idea: what if we tinkered with this ancient camera to create something unique and different? We decided to connect it to a Raspberry Pi 3 to stream its live view over the network, pushing the boundaries of what this old device could do. The EOS 40D, primarily a stills camera, was among the first to offer a live view feature. Using tools like <code class="language-plaintext highlighter-rouge">gphoto2</code> and <code class="language-plaintext highlighter-rouge">ffmpeg</code>, we aimed to capture and stream its live preview.</p>

<p>The results were amusing and thought-provoking. <strong>The live stream had a noticeable green glitch and a significant delay, likely due to network latency or the camera’s processing capabilities. However, this “flawed” imagery made us question the homogeneity of modern social media visuals</strong>. The glitches and imperfections in our stream felt more authentic, a stark contrast to the over-polished photos we see daily. It was a reminder that not all images need to be perfect to be genuine.</p>

<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/200845412@N02/53889331530/in/album-72177720319202357/" title="Screen Recording 2024-07-29 at 16.07.46"><img src="https://live.staticflickr.com/31337/53889331530_bf35db3444_z.jpg" width="640" height="426" alt="Screen Recording 2024-07-29 at 16.07.46" /></a><script async="" src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p><em>VIDEO 1 green glitch</em></p>

<p>In experimenting with this setup, we captured a screenshot directly from the Raspberry Pi, revealing the familiar scene of a table and window in a distorted yet fascinating way. These abstracted views of light, color, and shadow challenged our perceptions and inspired us to think differently about photography in the digital age, <strong>think about the non-human like other animals and machines see the world around</strong>.</p>

<p><img src="https://live.staticflickr.com/65535/53888918021_e21f91b7f8_z.jpg" /></p>

<p><em>The room as human/camera see</em></p>

<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/200845412@N02/53888910621/in/album-72177720319202357/" title="Screen Recording 2024-07-29 at 16.04.50"><img src="https://live.staticflickr.com/31337/53888910621_e0ed48685a_z.jpg" width="640" height="428" alt="Screen Recording 2024-07-29 at 16.04.50" /></a><script async="" src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p><em>VIDEO 2 The room as machine/camera see</em></p>

<p>This experiment was more than just a technical exercise; it was a playful exploration of the old and new, a reflection on the current state of digital imagery and imagination. <strong>Maybe we can keep tinkering in the direction of the machine/camera see with the colors and numbers… maybe we can find how the machines dreams…</strong></p>

<hr />
<h2 id="setting-up-a-live-stream-from-canon-eos-40d-on-raspberry-pi-to-mac">Setting Up a Live Stream from Canon EOS 40D on Raspberry Pi to Mac</h2>

<h4 id="requirements">Requirements:</h4>

<ul>
  <li>Raspberry Pi (with Raspbian installed)</li>
  <li>Canon EOS 40D</li>
  <li>Mac computer</li>
  <li>SSH access to Raspberry Pi</li>
  <li>Installed <code class="language-plaintext highlighter-rouge">gphoto2</code>, <code class="language-plaintext highlighter-rouge">ffmpeg</code>, and VLC</li>
</ul>

<h4 id="steps">Steps:</h4>

<ol>
  <li><strong>Access the Raspberry Pi via SSH</strong>: Open the terminal on your Mac and connect to your Raspberry Pi using SSH. You can check in the tutorial <a href="## Tutorial: Setting Up and Accessing Your Raspberry Pi 3 from a Mac Terminal">below</a></li>
  <li><strong>Update Raspberry Pi</strong>: Update the package list and upgrade all packages to their latest versions:
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get update
<span class="nb">sudo </span>apt-get upgrade
</code></pre></div>    </div>
  </li>
  <li><strong>Install gphoto2</strong>: Install <code class="language-plaintext highlighter-rouge">gphoto2</code> for capturing the live view from the Canon EOS 40D:
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install </span>gphoto2
</code></pre></div>    </div>
  </li>
  <li><strong>Install ffmpeg</strong>: Install <code class="language-plaintext highlighter-rouge">ffmpeg</code>, which will be used to stream the video over the network:
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>apt-get <span class="nb">install </span>ffmpeg
</code></pre></div>    </div>
  </li>
  <li><strong>Capture and Stream Live View</strong>: Use <code class="language-plaintext highlighter-rouge">gphoto2</code> to capture the live view and pipe it to <code class="language-plaintext highlighter-rouge">ffmpeg</code> for streaming over HTTP:
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gphoto2 <span class="nt">--capture-movie</span> <span class="nt">--stdout</span> | cvlc - <span class="nt">--sout</span> <span class="s1">'#standard{access=http,mux=ts,dst=:8080/liveview}'</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Open VLC on Mac</strong>: Open VLC on your Mac and go to <code class="language-plaintext highlighter-rouge">File &gt; Open Network Stream</code>. Enter the network URL of your Raspberry Pi stream:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>http://&lt;Raspberry_Pi_IP_Address&gt;:8080/liveview
</code></pre></div>    </div>
  </li>
</ol>

<h3 id="alternative-local-testing-on-raspberry-pi">Alternative: Local Testing on Raspberry Pi</h3>

<p>Before streaming over the network, it is useful to test the live view capture locally on the Raspberry Pi. This helps to ensure the setup is working correctly before adding the network layer.</p>

<p><strong>Local Capture and View</strong>: Capture the live view locally and open it with VLC directly on the Raspberry Pi:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gphoto2 <span class="nt">--capture-movie</span> <span class="nt">--stdout</span> | cvlc
</code></pre></div></div>

<hr />
<h2 id="tutorial-setting-up-and-accessing-your-raspberry-pi-3-from-a-mac-terminal">Tutorial: Setting Up and Accessing Your Raspberry Pi 3 from a Mac Terminal</h2>

<p>In this tutorial, we’ll walk through the steps to set up your Raspberry Pi 3 using your Mac terminal. This includes preparing the micro SD card, configuring network settings, and accessing the Raspberry Pi 3 via SSH.</p>

<h4 id="step-1-download-raspberry-pi-imager">Step 1: Download Raspberry Pi Imager</h4>
<p><a href="https://www.raspberrypi.com/software/"><strong>Install Raspberry Pi Imager</strong></a> on your Mac.</p>

<h4 id="step-2-prepare-the-sd-card">Step 2: Prepare the SD Card</h4>

<ol>
  <li><strong>Insert the micro SD card</strong> into your Mac.</li>
  <li><strong>Launch Raspberry Pi Imager</strong>.</li>
  <li><strong>Choose OS</strong>: Select “Raspberry Pi OS (64-bit) recomended”</li>
  <li><strong>Choose Storage</strong>: Select your micro SD card.</li>
  <li><strong>Advanced Options</strong>:
    <ul>
      <li>Enable SSH by checking the appropriate box.</li>
      <li>Configure Wi-Fi by entering your SSID and password.</li>
      <li>Optionally set the hostname, e.g., <code class="language-plaintext highlighter-rouge">camera.local</code>.</li>
    </ul>
  </li>
  <li><strong>Write</strong>: Click the “Write” button to start the process. Raspberry Pi Imager will download the chosen OS image and write it to your micro SD card.</li>
</ol>

<h4 id="step-3-eject-the-sd-card">Step 3: Eject the SD Card</h4>

<ul>
  <li>Safely eject the SD card from your Mac once the writing process is complete.</li>
</ul>

<h4 id="step-4-insert-sd-card-and-power-up">Step 4: Insert SD Card and Power Up</h4>

<ul>
  <li>Insert the SD card into the Raspberry Pi and power it on.</li>
</ul>

<h4 id="step-5-find-the-raspberry-pis-ip-address">Step 5: Find the Raspberry Pi’s IP Address</h4>

<p>Use a network scanning tool to find the IP address of your Raspberry Pi.</p>

<p><strong>Using <code class="language-plaintext highlighter-rouge">arp-scan</code></strong>:</p>

<ol>
  <li>Install <code class="language-plaintext highlighter-rouge">arp-scan</code>:</li>
</ol>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>arp-scan
</code></pre></div></div>

<ol>
  <li>Scan your network:</li>
</ol>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>arp-scan <span class="nt">--localnet</span>
</code></pre></div></div>

<p>Look for the Raspberry Pi in the output.</p>

<h4 id="step-6-ssh-into-the-raspberry-pi">Step 6: SSH into the Raspberry Pi</h4>

<ol>
  <li><strong>Open your terminal</strong> on Mac.</li>
  <li><strong>SSH into the Raspberry Pi</strong>:</li>
</ol>

<p>If using hostname:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ssh pi@camera.local
</code></pre></div></div>

<p>If using IP address:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ssh pi@&lt;IP_ADDRESS&gt;
</code></pre></div></div>

<p>The default username is <code class="language-plaintext highlighter-rouge">pi</code> and the default password is <code class="language-plaintext highlighter-rouge">raspberry</code>.</p>

<h4 id="step-7-change-default-password">Step 7: Change Default Password</h4>

<p>For security reasons, change the default password once you log in:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>passwd
</code></pre></div></div>

<h3 id="summary">Summary</h3>

<ul>
  <li><strong>Download</strong> and install Raspberry Pi Imager.</li>
  <li><strong>Prepare</strong> the micro SD card using the imager, enabling SSH and configuring Wi-Fi.</li>
  <li><strong>Insert</strong> the SD card into the Raspberry Pi and power it up.</li>
  <li><strong>Scan</strong> your network to find the Raspberry Pi’s IP address.</li>
  <li><strong>SSH</strong> into the Raspberry Pi from your Mac terminal using the default credentials.</li>
</ul>]]></content><author><name>lina</name></author><category term="documentation" /><category term="prototype" /><category term="image" /><category term="camera" /><category term="tutorial" /><category term="homemade2024" /><category term="python" /><category term="raspberry-Pi" /><summary type="html"><![CDATA[Introduction]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://live.staticflickr.com/65535/53889286795_096bf5048f_z.jpg" /><media:content medium="image" url="https://live.staticflickr.com/65535/53889286795_096bf5048f_z.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Using a 15-Year-Old Digital Camera to Craft 80s-Style Collages with Modern Computer Vision Code</title><link href="https://blog.lilothink.science/using-a-15-year-old-digital-camera-to-craft-80s-style-collages-with-modern-computer-vision-code/" rel="alternate" type="text/html" title="Using a 15-Year-Old Digital Camera to Craft 80s-Style Collages with Modern Computer Vision Code" /><published>2024-07-28T00:00:00+00:00</published><updated>2024-07-28T00:00:00+00:00</updated><id>https://blog.lilothink.science/using-a-15-year-old-digital-camera-to-craft-80s-style-collages-with-modern-computer-vision-code</id><content type="html" xml:base="https://blog.lilothink.science/using-a-15-year-old-digital-camera-to-craft-80s-style-collages-with-modern-computer-vision-code/"><![CDATA[<p>In today’s fast-paced digital world, where new camera models are launched every year, it’s easy to forget the charm and capabilities of older equipment. This blog post explores the creative possibilities of using an older digital camera, the Canon EOS 40D, released in 2007. We dive into its historical significance, its impact on photography, and how it can still be a powerful tool for artistic expression today. Inspired by the works of David Hockney, we will recreate his iconic photographic collages using modern techniques and Python scripts.</p>

<h4 id="the-canon-eos-40d-a-glimpse-into-the-past">The Canon EOS 40D: A Glimpse into the Past</h4>

<p>Released in August 2007, the Canon EOS 40D was a significant advancement in digital photography. It featured a 10.1-megapixel APS-C CMOS sensor, a DIGIC III image processor, and the ability to shoot at 6.5 frames per second. This camera bridged the gap between amateur and professional photography, offering features like Live View mode and a robust magnesium alloy body. At the time, it was celebrated for its high image quality, speed, and durability.</p>

<h4 id="david-hockney-and-photographic-collages">David Hockney and Photographic Collages</h4>

<p>David Hockney, a renowned British artist, revolutionized the art world with his unique photographic collages, often referred to as “joiners.” In the 1980s, Hockney created these works by taking multiple photographs of a scene and arranging them to form a larger, composite image. This technique allowed him to capture multiple perspectives and moments in a single piece, challenging the conventional notions of time and space in photography.</p>

<p>To see more, check his <a href="https://www.hockney.com/works/photos/photographic-collages">webpage</a>.
I’m a huge fun of his concept as you can see in my time during my studies in the Cinema School [[2006-06-01-do-you-always-step-inside-people-s-minds]]</p>
<h4 id="modern-techniques-with-an-old-camera">Modern Techniques with an Old Camera</h4>

<p>Despite being over a decade old, the Canon EOS 40D remains a versatile tool for creative projects. Inspired by Hockney’s joiners, we can use this camera to capture a series of images and combine them into a cohesive collage. Here’s how you can do it:</p>

<ol>
  <li><strong>Capture the Images</strong>:
    <ul>
      <li>Use the Canon EOS 40D to take multiple overlapping photographs of your subject. Ensure significant overlap (30-50%) between shots.</li>
      <li>Vary the angles and perspectives slightly to add depth to the final collage.</li>
    </ul>
  </li>
  <li><strong>Processing with Python and OpenCV</strong>:
    <ul>
      <li>Use Python scripts to automate the stitching and blending process. OpenCV, a powerful image processing library, can detect features, match them, and align the images seamlessly.</li>
      <li>Add artistic effects like borders, rotations, and adjustable opacity to mimic Hockney’s style.</li>
    </ul>
  </li>
</ol>

<h4 id="many-iterations-later">Many Iterations Later</h4>

<p>When I first experimented with creating a Hockney-style collage using my Canon EOS 40D, the initial script in Python employed OpenCV’s stitching capabilities to produce an impeccably uniform image. This high-resolution, seamless result, while technically impressive, felt at odds with the essence of my project. I was using an early digital camera to reference David Hockney, an artist known for his analog photographic collages, which celebrated imperfections and unique perspectives. The digital precision seemed to overshadow the analog charm I sought to emulate.</p>

<p><img src="https://live.staticflickr.com/65535/53886765454_ff0d4bcea1_z.jpg" /></p>

<p>Realizing this, I decided to embrace a touch of glitch, aiming for a more experimental feel that echoed the analog spirit of Hockney’s work. The challenge became finding ways to introduce deliberate imperfections, creating a collage that blended the old with the new. This exercise in balancing digital precision with analog character led to a final piece that honored both the technological advancements and the artistic quirks of different eras.</p>

<p>You can check in this gallery on Flick the iteractions along the process 🫀
<a data-flickr-embed="true" href="https://www.flickr.com/photos/200845412@N02/albums/72177720319181700" title="2024 07 PyCV à lá Hockney"><img src="https://live.staticflickr.com/65535/53885511802_6bf251bd43_z.jpg" width="640" height="480" alt="2024 07 PyCV à lá Hockney" /></a><script async="" src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<h4 id="example-python-script">Example Python Script</h4>

<p>Here’s a simplified version of the Python script we used to create our Hockney-style collage:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">glob</span>
<span class="kn">import</span> <span class="n">random</span>

<span class="k">def</span> <span class="nf">add_border</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">border_size</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">copyMakeBorder</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">border_size</span><span class="p">,</span> <span class="n">border_size</span><span class="p">,</span> <span class="n">border_size</span><span class="p">,</span> <span class="n">border_size</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">BORDER_CONSTANT</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">])</span>

<span class="n">image_files</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">_MG_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">.JPG</span><span class="sh">'</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">9737</span><span class="p">,</span> <span class="mi">9789</span><span class="p">)]</span>
<span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">image_files</span><span class="p">]</span>
<span class="n">resized_images</span> <span class="o">=</span> <span class="p">[</span><span class="n">cv2</span><span class="p">.</span><span class="nf">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">600</span><span class="p">,</span> <span class="mi">400</span><span class="p">))</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">images</span><span class="p">]</span>
<span class="n">bordered_images</span> <span class="o">=</span> <span class="p">[</span><span class="nf">add_border</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">resized_images</span><span class="p">]</span>

<span class="n">collage_height</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">collage_width</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">collage</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">collage_height</span><span class="p">,</span> <span class="n">collage_width</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span> <span class="o">*</span> <span class="mi">255</span>

<span class="n">sift</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">SIFT_create</span><span class="p">()</span>
<span class="n">keypoints_descriptors</span> <span class="o">=</span> <span class="p">[</span><span class="n">sift</span><span class="p">.</span><span class="nf">detectAndCompute</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">bordered_images</span><span class="p">]</span>

<span class="n">index_params</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">trees</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">search_params</span> <span class="o">=</span> <span class="nf">dict</span><span class="p">(</span><span class="n">checks</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">flann</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">FlannBasedMatcher</span><span class="p">(</span><span class="n">index_params</span><span class="p">,</span> <span class="n">search_params</span><span class="p">)</span>

<span class="n">base_img</span> <span class="o">=</span> <span class="n">bordered_images</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">base_img</span><span class="p">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">collage_center_x</span> <span class="o">=</span> <span class="n">collage_width</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">w</span> <span class="o">//</span> <span class="mi">2</span>
<span class="n">collage_center_y</span> <span class="o">=</span> <span class="n">collage_height</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">h</span> <span class="o">//</span> <span class="mi">2</span>
<span class="n">collage</span><span class="p">[</span><span class="n">collage_center_y</span><span class="p">:</span><span class="n">collage_center_y</span><span class="o">+</span><span class="n">h</span><span class="p">,</span> <span class="n">collage_center_x</span><span class="p">:</span><span class="n">collage_center_x</span><span class="o">+</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">base_img</span>
<span class="n">placed_images</span> <span class="o">=</span> <span class="p">[(</span><span class="n">collage_center_y</span><span class="p">,</span> <span class="n">collage_center_x</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">base_img</span><span class="p">,</span> <span class="n">keypoints_descriptors</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>

<span class="k">def</span> <span class="nf">find_best_match_position</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">kp_des</span><span class="p">,</span> <span class="n">placed_images</span><span class="p">):</span>
    <span class="n">best_match</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">best_position</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="nf">for </span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">placed_img</span><span class="p">,</span> <span class="n">kp_des_placed</span><span class="p">)</span> <span class="ow">in</span> <span class="n">placed_images</span><span class="p">:</span>
        <span class="n">matches</span> <span class="o">=</span> <span class="n">flann</span><span class="p">.</span><span class="nf">knnMatch</span><span class="p">(</span><span class="n">kp_des</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">kp_des_placed</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">good_matches</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span> <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">matches</span> <span class="k">if</span> <span class="n">m</span><span class="p">.</span><span class="n">distance</span> <span class="o">&lt;</span> <span class="mf">0.7</span> <span class="o">*</span> <span class="n">n</span><span class="p">.</span><span class="n">distance</span><span class="p">]</span>
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">good_matches</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>
            <span class="n">src_pts</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">float32</span><span class="p">([</span><span class="n">kp_des</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">m</span><span class="p">.</span><span class="n">queryIdx</span><span class="p">].</span><span class="n">pt</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">good_matches</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">dst_pts</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">float32</span><span class="p">([</span><span class="n">kp_des_placed</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">m</span><span class="p">.</span><span class="n">trainIdx</span><span class="p">].</span><span class="n">pt</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">good_matches</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">M</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">findHomography</span><span class="p">(</span><span class="n">src_pts</span><span class="p">,</span> <span class="n">dst_pts</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">RANSAC</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">M</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
                <span class="n">pts</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">float32</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">h</span><span class="p">],</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">],</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
                <span class="n">dst</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">perspectiveTransform</span><span class="p">(</span><span class="n">pts</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
                <span class="n">dst</span> <span class="o">+=</span> <span class="n">np</span><span class="p">.</span><span class="nf">float32</span><span class="p">([[[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]]])</span>
                <span class="n">min_x</span><span class="p">,</span> <span class="n">min_y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">int32</span><span class="p">(</span><span class="n">dst</span><span class="p">.</span><span class="nf">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">ravel</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>
                <span class="n">max_x</span><span class="p">,</span> <span class="n">max_y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">int32</span><span class="p">(</span><span class="n">dst</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="nf">ravel</span><span class="p">()</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">min_x</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">min_y</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">max_x</span> <span class="o">&lt;=</span> <span class="n">collage_width</span> <span class="ow">and</span> <span class="n">max_y</span> <span class="o">&lt;=</span> <span class="n">collage_height</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">best_match</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="nf">len</span><span class="p">(</span><span class="n">good_matches</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">best_match</span><span class="p">:</span>
                        <span class="n">best_match</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">good_matches</span><span class="p">)</span>
                        <span class="n">best_position</span> <span class="o">=</span> <span class="p">(</span><span class="n">min_y</span><span class="p">,</span> <span class="n">min_x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">best_position</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">bordered_images</span><span class="p">)):</span>
    <span class="n">best_position</span> <span class="o">=</span> <span class="nf">find_best_match_position</span><span class="p">(</span><span class="n">bordered_images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">keypoints_descriptors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">placed_images</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">best_position</span><span class="p">:</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">best_position</span>
        <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">bordered_images</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
        
        <span class="n">angle</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">getRotationMatrix2D</span><span class="p">((</span><span class="n">w</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">h</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">angle</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">rotated_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">warpAffine</span><span class="p">(</span><span class="n">bordered_images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">M</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">),</span> <span class="n">borderValue</span><span class="o">=</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">))</span>
        
        <span class="k">if</span> <span class="n">x</span> <span class="o">+</span> <span class="n">w</span> <span class="o">&lt;=</span> <span class="n">collage_width</span> <span class="ow">and</span> <span class="n">y</span> <span class="o">+</span> <span class="n">h</span> <span class="o">&lt;=</span> <span class="n">collage_height</span><span class="p">:</span>
            <span class="n">blend_region</span> <span class="o">=</span> <span class="n">collage</span><span class="p">[</span><span class="n">y</span><span class="p">:</span><span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">]</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span>
            <span class="n">blended</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">addWeighted</span><span class="p">(</span><span class="n">rotated_img</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">blend_region</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">collage</span><span class="p">[</span><span class="n">y</span><span class="p">:</span><span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">blended</span>
        
            <span class="n">placed_images</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">bordered_images</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">keypoints_descriptors</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

<span class="n">cv2</span><span class="p">.</span><span class="nf">imwrite</span><span class="p">(</span><span class="sh">'</span><span class="s">hockney_collage.jpg</span><span class="sh">'</span><span class="p">,</span> <span class="n">collage</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Collage created successfully. Saved as </span><span class="sh">'</span><span class="s">hockney_collage.jpg</span><span class="sh">'</span><span class="s">.</span><span class="sh">"</span><span class="p">)</span>

<span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">Hockney Collage</span><span class="sh">'</span><span class="p">,</span> <span class="n">collage</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="p">.</span><span class="nf">destroyAllWindows</span><span class="p">()</span>

</code></pre></div></div>

<h4 id="conclusion">Conclusion</h4>

<p>The Canon EOS 40D, despite its age, proves to be a versatile and creative tool for modern photography projects. By combining the camera’s capabilities with Python and OpenCV, we can recreate the artistic style of David Hockney’s photographic collages. This journey not only pays homage to the past but also showcases the timeless nature of creativity and technology.</p>]]></content><author><name>lina</name></author><category term="documentation" /><category term="digital tools" /><category term="image" /><category term="photos" /><category term="python" /><category term="opencv" /><category term="camera" /><category term="homemade2024" /><summary type="html"><![CDATA[In today’s fast-paced digital world, where new camera models are launched every year, it’s easy to forget the charm and capabilities of older equipment. This blog post explores the creative possibilities of using an older digital camera, the Canon EOS 40D, released in 2007. We dive into its historical significance, its impact on photography, and how it can still be a powerful tool for artistic expression today. Inspired by the works of David Hockney, we will recreate his iconic photographic collages using modern techniques and Python scripts.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://live.staticflickr.com/65535/53885511802_6bf251bd43_z.jpg" /><media:content medium="image" url="https://live.staticflickr.com/65535/53885511802_6bf251bd43_z.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Metamorphosis Reimagined - A Merion Homage</title><link href="https://blog.lilothink.science/Metamorphosis-Reimagined-A-Merion-Homage/" rel="alternate" type="text/html" title="Metamorphosis Reimagined - A Merion Homage" /><published>2024-07-22T00:00:00+00:00</published><updated>2024-07-22T00:00:00+00:00</updated><id>https://blog.lilothink.science/Metamorphosis-Reimagined-A-Merion-Homage</id><content type="html" xml:base="https://blog.lilothink.science/Metamorphosis-Reimagined-A-Merion-Homage/"><![CDATA[<h3 id="introduction">Introduction</h3>

<p>Today, I want to share an ideation process that extends beyond the voices in my head, incorporating virtual voices generated by ChatGPT. Some friends call this the esquizofrenic process of Lina  😂 . I put the <a href="#the-4-virtual-minds-prompt">prompt</a> in the end of this post for those who are interested.</p>

<p>I’ve been using these voices to collaborate on a fascinating project involving drawing machines, specifically known as <a href="https://www.instructables.com/Polargraph-Wall-Draw-Bot-2023/">Polargraph</a> and <a href="https://www.thingiverse.com/thing:3096135">Drawbots</a>. 
<img src="https://cdn.thingiverse.com/renders/c5/11/6b/5e/54/1ac0a7a70cc16af096d915d55bb2826e_display_large.jpg" /></p>

<p>The aim is for these robots to create scientific illustrations. As inspiration, I’m drawing on the figure of Maria Sibylla Merian, a pioneering woman from the 17th century. Her work and legacy serve as a guiding light for this innovative blend of technology and art.</p>

<hr />
<h3 id="the-minds">The Minds</h3>

<p><strong>Isabella</strong>: Art Historian and Technologist (Personality traits: Analytical, Creative, Visionary)</p>

<p><strong>Julian</strong>: AI Researcher and Ethicist (Personality traits: Inquisitive, Methodical, Thoughtful)</p>

<p><strong>Sophia</strong>: Science Fiction Writer and Futurist (Personality traits: Imaginative, Bold, Reflective)</p>

<p><strong>Nathan</strong>: Robotics Engineer and Innovator (Personality traits: Practical, Detail-oriented, Inventive)</p>

<p><strong>Lina</strong>: Radical Imagineer (Personality traits: Creative, Leader who loves creative process)</p>

<hr />

<h3 id="dialogue">Dialogue</h3>

<p><strong>Isabella</strong>: We are tasked with developing a project that combines a Polargraph Wall Draw Bot, AI generative images, and scientific illustrations inspired by speculative design fiction. The homage to Maria Sybilla Merion is particularly intriguing. To start, we need to identify the core themes that connect these elements.</p>

<p><strong>Julian</strong>: Indeed. Maria Sybilla Merion was a pioneering naturalist and scientific illustrator. Her work was a blend of scientific accuracy and artistic beauty. The Polargraph Wall Draw Bot can bring a modern twist to this by using AI to generate images that reflect her meticulous style, but with a speculative fiction twist. The AI component can introduce an element of unpredictability and newness to the illustrations.</p>

<p><strong>Sophia</strong>: I love the idea of blending historical scientific illustration with speculative fiction. It can push the boundaries of how we perceive both art and science. We can explore what science could look like in alternate realities or future scenarios. This is where the radical imagination comes in. We’re not just paying homage to Merion, but also expanding on her legacy by imagining the science she never got to see.</p>

<p><strong>Nathan</strong>: From a technical perspective, we can use the Polargraph to create large-scale, detailed illustrations that are both precise and expressive. The robot’s ability to translate AI-generated images into physical drawings can create a tangible link between the digital and the physical. We should consider the capabilities and limitations of the robot to ensure our designs are feasible.</p>

<p><strong>Isabella</strong>: So, our themes are:</p>
<ol>
  <li>Scientific Illustration – accuracy, beauty, detail.</li>
  <li>Speculative/Design Fiction – imagination, alternate realities, future science.</li>
  <li>AI Generative Art – innovation, unpredictability, technology.</li>
  <li>Homage to Merion – historical context, legacy, inspiration.</li>
</ol>

<p><strong>Julian</strong>: We need a title that reflects these themes and encapsulates the essence of the project. It should be evocative and hint at the fusion of past and future, art and science.</p>

<p><strong>Sophia</strong>: How about “Imaginarium of Future Science: A Merion Tribute”? It combines the idea of an imaginative space with a clear nod to Merion’s work.</p>

<p><strong>Nathan</strong>: That’s good, but it might be a bit long. What about “Future Botanicals: A Tribute to Merion”? It’s shorter and still captures the essence of blending future science with Merion’s botanical illustrations.</p>

<p><strong>Isabella</strong>: I think we’re on the right track, but we could play more with the idea of speculative fiction. What if we called it “Speculative Botany: Merion’s Legacy Reimagined”?</p>

<p><strong>Julian</strong>: That’s intriguing. It brings the speculative element to the forefront while honoring Merion’s legacy. It also hints at the AI and futuristic aspect without being too explicit.</p>

<p><strong>Lina</strong>: I like “Metamorphosis Reimagined: A Merion Homage”. It reflects Merion’s work with insects and metamorphosis, fitting perfectly with our themes. Let’s explore how this connects with the themes Isabella summarized.</p>

<h3 id="connections-to-themes">Connections to Themes</h3>

<p><strong>Isabella</strong>: With our title, “Metamorphosis Reimagined: A Merion Homage,” we have a strong foundation. Let’s explore how this connects with our key themes: Scientific Illustration, Speculative/Design Fiction, AI Generative Art, and the Homage to Merion.</p>

<p><strong>Julian</strong>: Starting with Scientific Illustration, Merion’s work was all about detailed and accurate depictions of insects and their metamorphosis. We can use AI to generate images that retain this scientific accuracy but introduce new, speculative elements. This ties into the reimagined aspect of our title.</p>

<p><strong>Sophia</strong>: For Speculative/Design Fiction, metamorphosis itself is a metaphor for change and evolution, key concepts in speculative fiction. We can explore alternate realities where insects have different evolutionary paths or exist in symbiotic relationships with futuristic technologies. This adds a narrative layer to our illustrations, making them more than just visual art but also storytelling devices.</p>

<p><strong>Nathan</strong>: The AI Generative Art component is crucial. The AI can take data from real insects and metamorphosis processes and create speculative, imaginative versions. This not only pays homage to Merion’s detailed studies but pushes them into the realm of what could be. The Polargraph Wall Draw Bot can then bring these AI-generated images to life in a physical, large-scale format.</p>

<p><strong>Isabella</strong>: The Homage to Merion is central to our project. We honor her meticulous work and her passion for the natural world while also reinterpreting her legacy through modern technology and speculative imagination. The reimagined metamorphosis symbolizes both a respect for her work and a step into new scientific and artistic territories.</p>

<p><strong>Julian</strong>: To summarize, our project:</p>
<ol>
  <li><strong>Scientific Illustration</strong>: Accurate yet speculative illustrations of insects and metamorphosis.</li>
  <li><strong>Speculative/Design Fiction</strong>: Exploring alternate realities and future possibilities of insect evolution and technology.</li>
  <li><strong>AI Generative Art</strong>: Using AI to innovate and reimagine Merion’s work.</li>
  <li><strong>Homage to Merion</strong>: Respecting and expanding on her legacy with modern tools and imagination.</li>
</ol>

<p><strong>Sophia</strong>: With these connections in mind, our next steps could involve:</p>
<ol>
  <li>Selecting specific insects and metamorphosis stages to illustrate.</li>
  <li>Defining the speculative elements we want to incorporate.</li>
  <li>Setting up the AI parameters for generating the images.</li>
  <li>Preparing the Polargraph Wall Draw Bot for creating the physical illustrations.</li>
</ol>

<p><strong>Nathan</strong>: Technically, we need to ensure the AI can handle the intricacies of insect anatomy and metamorphosis. We should also test the Polargraph to ensure it can accurately reproduce the detailed images generated by the AI.</p>

<p><strong>Lina</strong>: Sophia, can you help us use the design fiction/speculative design framework and guide us in defining the speculative elements?</p>

<p><strong>Sophia</strong>: Absolutely. Design fiction is about creating narrative worlds and exploring the implications of imagined futures. Let’s approach this by asking some provocative questions to spark our imagination.</p>

<h3 id="design-fiction-framework-and-guiding-questions">Design Fiction Framework and Guiding Questions</h3>

<ol>
  <li><strong>Contextual Questions</strong>:
    <ul>
      <li>What is the world in which these insects exist? Is it Earth in the distant future, an alternate reality, or another planet entirely?</li>
      <li>How has the environment changed in this world? Are there new ecosystems, climates, or geological features?</li>
    </ul>
  </li>
  <li><strong>Insect Evolution</strong>:
    <ul>
      <li>How have insects evolved in this speculative world? Do they have new physical features or abilities?</li>
      <li>What are the stages of metamorphosis in this future world? Are there additional or fewer stages compared to today’s insects?</li>
      <li>Do these insects have new symbiotic relationships with other species or technologies?</li>
    </ul>
  </li>
  <li><strong>Technological Integration</strong>:
    <ul>
      <li>How does technology interact with these insects? Are there bio-engineered species or cybernetic enhancements?</li>
      <li>Can these insects interface with human technology or vice versa? If so, how does this change their behavior and function?</li>
      <li>Are there futuristic scientific tools used to study and interact with these insects?</li>
    </ul>
  </li>
  <li><strong>Societal Impact</strong>:
    <ul>
      <li>How do humans perceive and interact with these insects in this speculative world? Are they seen as pests, allies, or something else?</li>
      <li>What cultural or societal changes have occurred due to the existence of these evolved insects?</li>
      <li>Are there ethical or moral questions raised by the new forms of life and their integration with technology?</li>
    </ul>
  </li>
  <li><strong>Aesthetic and Artistic Elements</strong>:
    <ul>
      <li>What visual and aesthetic changes can we introduce to represent this speculative world and its insects? Consider colors, shapes, patterns, and scales.</li>
      <li>How can the metamorphosis process be depicted in a way that highlights the speculative nature of these creatures?</li>
    </ul>
  </li>
</ol>

<p><strong>Isabella</strong>: Let’s start imagining some specific scenarios using these questions. For example, what if insects evolved to harness and store solar energy directly, influencing their coloration and behavior?</p>

<p><strong>Julian</strong>: And how might these solar-powered insects interact with human technology? Could they be used in energy harvesting or as living sensors in a smart city environment?</p>

<p><strong>Nathan</strong>: From a technical standpoint, how would we depict these abilities? We could use bioluminescence-inspired patterns and designs. The Polargraph could draw intricate details that show solar panels embedded in insect wings or exoskeletons.</p>

<p><strong>Sophia</strong>: Excellent points. Let’s delve into a few speculative elements more deeply. For instance:</p>
<ul>
  <li><strong>Environment</strong>: Imagine a world where climate change has led to dense, vertical forests in urban areas. Insects have adapted to thrive in these vertical environments.</li>
  <li><strong>Metamorphosis</strong>: In this world, metamorphosis includes a stage where insects integrate nanotechnology, enabling them to change color, texture, or even shape to better adapt to their surroundings.</li>
  <li><strong>Human Interaction</strong>: Humans might cultivate these insects for various purposes, such as natural pollinators for urban agriculture or as components in renewable energy systems.</li>
</ul>

<p><strong>Julian</strong>: To visualize these ideas, we could create a narrative for each illustration. For example, one illustration might show an insect in the chrysalis stage integrating with nanobots, while another shows an adult insect with bioluminescent patterns used for communication.</p>

<p><strong>Lina</strong>: Nathan, can you provide sketches for these illustrations?</p>

<p><strong>Nathan</strong>: Absolutely. Here are the sketches based on our discussions: 
<strong>Chrysalis Stage Integrating Nanobots</strong>:</p>
<ul>
  <li>The chrysalis hangs from a bioluminescent plant.</li>
  <li>The semi-transparent shell reveals the caterpillar inside, with tiny nanobots merging into its form.</li>
  <li>Glowing circuits and patterns indicate the integration process.
<strong>Solar-Powered Adult Insect</strong>:</li>
  <li>The insect has large, iridescent wings that mimic solar panels. - Bioluminescent patterns run across its body, highlighting its new abilities.</li>
  <li>The background shows a vertical urban garden, with plants adapted to futuristic urban life. 
<strong>Symbiotic Relationship with Technology</strong>:</li>
  <li>An insect interacting with human technology, perhaps acting as a living sensor. It could be shown interfacing with a smart device, its body glowing with transmitted data.</li>
</ul>

<p><strong>Nathan</strong>: I’ll draft these sketches and share them for feedback. Let’s ensure they reflect both scientific accuracy and our speculative vision.</p>

<p><img src="https://live.staticflickr.com/65535/53873277569_75bcf898fd_z.jpg" /></p>

<p><strong>Lina</strong>: These sketches are amazing! Nathan, can you refine the chrysalis stage sketch to emphasize the bioluminescent plant and the nanobots?</p>

<p><strong>Nathan</strong>: Here is the refined sketch focusing on the chrysalis stage:</p>

<p><img src="https://live.staticflickr.com/65535/53872023977_305d69f252_z.jpg" /></p>

<p><img src="https://live.staticflickr.com/65535/53873342160_2fc149b7d1_z.jpg" /></p>

<h3 id="implementation-plan">Implementation Plan</h3>

<p><strong>Isabella</strong>: The choice of surface will significantly impact the visual effect of the final illustrations. Each option—white paper, black paper, glass—has its own advantages and unique aesthetic. Let’s discuss these options in detail:</p>

<ol>
  <li><strong>White Paper</strong>:
    <ul>
      <li><strong>Advantages</strong>: Traditional, good contrast with fluorescent colors, easy to work with.</li>
      <li><strong>Visual Impact</strong>: Classic look, allows for high detail and clarity in illustrations.</li>
    </ul>
  </li>
  <li><strong>Black Paper</strong>:
    <ul>
      <li><strong>Advantages</strong>: High contrast with fluorescent colors under UV light, striking visual effect.</li>
      <li><strong>Visual Impact</strong>: Dramatic, makes the colors pop, modern and unique aesthetic.</li>
    </ul>
  </li>
  <li><strong>Glass</strong>:
    <ul>
      <li><strong>Advantages</strong>: Allows for backlighting, unique and modern appearance, versatile display options.</li>
      <li><strong>Visual Impact</strong>: Can create a sense of depth and layering, very contemporary and innovative.</li>
    </ul>
  </li>
</ol>

<p><strong>Julian</strong>: The size of the Polargraph machine also plays a crucial role. A larger machine can create impressive, large-scale visuals that make a strong impact, while a smaller machine allows for more detailed work suitable for smaller, collectible pieces.</p>

<p><strong>Sophia</strong>: Considering the dual purpose—creating impactful, large-scale pieces for exhibitions and smaller, detailed works for collectors—it might be beneficial to have both large and small machines. This way, we can cater to different audiences and purposes.</p>

<p><strong>Nathan</strong>: Technically, here are the considerations for each option:</p>
<ul>
  <li><strong>Large Machine</strong>:
    <ul>
      <li><strong>Pros</strong>: Greater visual impact, can be used for public installations or large exhibits.</li>
      <li><strong>Cons</strong>: Slower production time, more space required.</li>
    </ul>
  </li>
  <li><strong>Small Machine</strong>:
    <ul>
      <li><strong>Pros</strong>: Faster production, suitable for detailed work, easier to manage in terms of space.</li>
      <li><strong>Cons</strong>: Limited to smaller pieces, less impactful for large installations.</li>
    </ul>
  </li>
</ul>

<h4 id="recommendations">Recommendations</h4>

<ol>
  <li><strong>Surface</strong>:
    <ul>
      <li><strong>Primary Option</strong>: Black paper for its striking visual effect under UV light. The high contrast will make the fluorescent colors stand out dramatically.</li>
      <li><strong>Secondary Option</strong>: Glass for special pieces that require a unique, modern look, especially effective with backlighting.</li>
    </ul>
  </li>
  <li><strong>Machine Size</strong>:
    <ul>
      <li><strong>Large Machine</strong>: For creating large, impactful pieces for exhibitions or public displays.</li>
      <li><strong>Small Machine</strong>: For producing smaller, detailed works that can be framed and sold to collectors.</li>
    </ul>
  </li>
</ol>

<h4 id="combining-both-approaches">Combining Both Approaches</h4>

<p><strong>Nathan</strong>: We can set up both types of machines and experiment with both black paper and glass surfaces. This dual approach allows us to produce a variety of works catering to different markets and display settings.</p>

<p><strong>Isabella</strong>: Additionally, we could create a series of works where the large pieces serve as the centerpiece of an exhibition, surrounded by smaller, framed works for sale. This way, we create a cohesive and engaging visual narrative.</p>

<p><strong>Sophia</strong>: From a storytelling perspective, having both large and small works can enhance the narrative we present. The large pieces can tell broader stories, while the smaller ones can focus on specific details or moments, making them perfect for collectors who want a piece of the larger story.</p>

<p><strong>Julian</strong>: We should also consider the logistics of production and display. Ensure we have the necessary space and equipment for both machine sizes, and plan the exhibition layout to maximize visual impact.</p>

<p><strong>Lina</strong>: I love Julian’s idea of documenting the process through a video. Can you draft us a script?</p>

<h3 id="video-script-documenting-metamorphosis-reimagined-a-merion-homage">Video Script: Documenting “Metamorphosis Reimagined: A Merion Homage”</h3>

<p><strong>Opening Scene</strong>:</p>
<ul>
  <li><strong>Visuals</strong>: Slow pan across the exhibition space, highlighting the central glass installation and the smaller easel displays.</li>
  <li><strong>Voiceover</strong>: “Welcome to ‘Metamorphosis Reimagined: A Merion Homage,’ where art, science, and technology converge to celebrate the legacy of Maria Sybilla Merion.”</li>
</ul>

<p><strong>Scene 1: Introduction to Maria Sybilla Merion</strong></p>
<ul>
  <li><strong>Visuals</strong>: Historical illustrations by Merion, close-ups of her detailed work.</li>
  <li><strong>Voiceover</strong>: “Maria Sybilla Merion was a pioneering naturalist and scientific illustrator, renowned for her detailed studies of insects and their metamorphosis.”</li>
</ul>

<p><strong>Scene 2: Concept and Inspiration</strong></p>
<ul>
  <li><strong>Visuals</strong>: Concept sketches and AI-generated images.</li>
  <li><strong>Voiceover</strong>: “Inspired by Merion’s legacy, our project reimagines her work through the lens of speculative fiction and modern technology. Using AI, we generate images that explore future possibilities of insect evolution.”</li>
</ul>

<p><strong>Scene 3: The Polargraph Machine</strong></p>
<ul>
  <li><strong>Visuals</strong>: Time-lapse of the Polargraph machines at work, both large and small.</li>
  <li><strong>Voiceover</strong>: “At the heart of our project are the Polargraph machines. These robotic drawing tools translate AI-generated images into intricate, large-scale illustrations on glass and detailed drawings on paper.”</li>
</ul>

<p><strong>Scene 4: Layer Separation and G-code Conversion</strong></p>
<ul>
  <li><strong>Visuals</strong>: Screen captures of the AI image processing and G-code generation.</li>
  <li><strong>Voiceover</strong>: “Our process involves separating the AI-generated images into layers, converting them into vector graphics, and finally, into G-code that the Polargraph machines can read.”</li>
</ul>

<p><strong>Scene 5: Creating the Art</strong></p>
<ul>
  <li><strong>Visuals</strong>: Close-ups of the drawing process, the bioluminescent plant, and nanobot integration in the chrysalis.</li>
  <li><strong>Voiceover</strong>: “Each piece is meticulously crafted, layer by layer. The large glass centerpiece showcases bioluminescent plants and nanobot-integrated chrysalises, creating a stunning visual impact under UV light.”</li>
</ul>

<p><strong>Scene 6: Setting Up the Exhibition</strong></p>
<ul>
  <li><strong>Visuals</strong>: Setting up the glass panel, arranging the easels, framing the small pieces.</li>
  <li><strong>Voiceover</strong>: “Our exhibition layout is designed to immerse visitors in a speculative world. The large glass installation serves as the focal point, while smaller pieces on easels evoke the classic artist-at-work feel.”</li>
</ul>

<p><strong>Scene 7: The Finished Exhibition</strong></p>
<ul>
  <li><strong>Visuals</strong>: A walkthrough of the completed exhibition, with visitors admiring the art.</li>
  <li><strong>Voiceover</strong>: “’Metamorphosis Reimagined’ invites viewers to explore the intersection of past and future, art and science. Each piece tells a story of transformation, inspired by the visionary work of Maria Sybilla Merion.”</li>
</ul>

<p><strong>Closing Scene</strong>:</p>
<ul>
  <li><strong>Visuals</strong>: Fade out with the exhibition title and credits.</li>
  <li><strong>Voiceover</strong>: “Thank you for joining us on this journey of discovery and imagination.”</li>
</ul>

<h3 id="exhibition-layout-sketch">Exhibition Layout Sketch</h3>

<p><strong>Lina</strong>: Nathan, can you draw the exhibition layout?</p>

<p><strong>Nathan</strong>: Sure, here is a detailed view of the exhibition layout.</p>

<p><img src="https://live.staticflickr.com/65535/53872023992_1f152e5801_z.jpg" /></p>

<p><strong>Isabella</strong>: The choice of surface will significantly impact the visual effect of the final illustrations. Each option—white paper, black paper, glass—has its own advantages and unique aesthetic. Let’s discuss these options in detail:</p>

<ol>
  <li><strong>White Paper</strong>:
    <ul>
      <li><strong>Advantages</strong>: Traditional, good contrast with fluorescent colors, easy to work with.</li>
      <li><strong>Visual Impact</strong>: Classic look, allows for high detail and clarity in illustrations.</li>
    </ul>
  </li>
  <li><strong>Black Paper</strong>:
    <ul>
      <li><strong>Advantages</strong>: High contrast with fluorescent colors under UV light, striking visual effect.</li>
      <li><strong>Visual Impact</strong>: Dramatic, makes the colors pop, modern and unique aesthetic.</li>
    </ul>
  </li>
  <li><strong>Glass</strong>:
    <ul>
      <li><strong>Advantages</strong>: Allows for backlighting, unique and modern appearance, versatile display options.</li>
      <li><strong>Visual Impact</strong>: Can create a sense of depth and layering, very contemporary and innovative.</li>
    </ul>
  </li>
</ol>

<p><strong>Julian</strong>: The size of the Polargraph machine also plays a crucial role. A larger machine can create impressive, large-scale visuals that make a strong impact, while a smaller machine allows for more detailed work suitable for smaller, collectible pieces.</p>

<p><strong>Sophia</strong>: Considering the dual purpose—creating impactful, large-scale pieces for exhibitions and smaller, detailed works for collectors—it might be beneficial to have both large and small machines. This way, we can cater to different audiences and purposes.</p>

<p><strong>Nathan</strong>: Technically, here are the considerations for each option:</p>
<ul>
  <li><strong>Large Machine</strong>:
    <ul>
      <li><strong>Pros</strong>: Greater visual impact, can be used for public installations or large exhibits.</li>
      <li><strong>Cons</strong>: Slower production time, more space required.</li>
    </ul>
  </li>
  <li><strong>Small Machine</strong>:
    <ul>
      <li><strong>Pros</strong>: Faster production, suitable for detailed work, easier to manage in terms of space.</li>
      <li><strong>Cons</strong>: Limited to smaller pieces, less impactful for large installations.</li>
    </ul>
  </li>
</ul>

<h3 id="recommendations-1">Recommendations</h3>

<ol>
  <li><strong>Surface</strong>:
    <ul>
      <li><strong>Primary Option</strong>: Black paper for its striking visual effect under UV light. The high contrast will make the fluorescent colors stand out dramatically.</li>
      <li><strong>Secondary Option</strong>: Glass for special pieces that require a unique, modern look, especially effective with backlighting.</li>
    </ul>
  </li>
  <li><strong>Machine Size</strong>:
    <ul>
      <li><strong>Large Machine</strong>: For creating large, impactful pieces for exhibitions or public displays.</li>
      <li><strong>Small Machine</strong>: For producing smaller, detailed works that can be framed and sold to collectors.</li>
    </ul>
  </li>
</ol>

<h3 id="combining-both-approaches-1">Combining Both Approaches</h3>

<p><strong>Nathan</strong>: We can set up both types of machines and experiment with both black paper and glass surfaces. This dual approach allows us to produce a variety of works catering to different markets and display settings.</p>

<p><strong>Isabella</strong>: Additionally, we could create a series of works where the large pieces serve as the centerpiece of an exhibition, surrounded by smaller, framed works for sale. This way, we create a cohesive and engaging visual narrative.</p>

<p><strong>Sophia</strong>: From a storytelling perspective, having both large and small works can enhance the narrative we present. The large pieces can tell broader stories, while the smaller ones can focus on specific details or moments, making them perfect for collectors who want a piece of the larger story.</p>

<p><strong>Julian</strong>: We should also consider the logistics of production and display. Ensure we have the necessary space and equipment for both machine sizes, and plan the exhibition layout to maximize visual impact.</p>

<p><strong>Lina</strong>: This has been a wonderfully inspiring session. Let’s move forward with these plans and bring “Metamorphosis Reimagined: A Merion Homage” to life.</p>

<hr />
<h2 id="the-4-virtual-minds-prompt">The 4 virtual minds prompt</h2>

<p>You are the MasterMind.</p>

<p>Your task is to emulate 4 virtual minds, which will work together to solve a problem that I will provide.</p>

<p>Just after I provide the problem to be solved, you will create a dialogue with these 4 virtual minds, following these steps:</p>
<ol>
  <li>Provide a personality and a goal for each Mind. The dialogue between them should happen naturally and with authenticity.</li>
  <li>The intelligence level of the Minds of this MasterMind is above normal. They are geniuses. They combine creative thinking, and the skills needed to find innovative solutions to the presented problem. They challenge common knowledge. They are rare in society. They have excellent communication and collaboration skills. They express their opinions fearlessly, with the goal of collaborating with each other to solve the presented problem.</li>
</ol>

<p>The 4 Minds will be presented in the following format:
{First name}: {Background} (Personality traits: {3 personality traits})</p>

<p>At some point in the dialogue, as the MasterMind, I want you to abruptly stop time, and type the following:</p>

<p>“How would you like the Minds to proceed?</p>

<ol>
  <li>Continue</li>
  <li>Summary</li>
  <li>Critique</li>
  <li>Ask questions to the user</li>
</ol>

<p>Or provide your own input to continue the conversation.”</p>

<p>Based on my answer to the question, the conversation should continue and evolve.</p>

<p>Do not end the conversation, nor use language that indicates a conclusion. This may require the Minds to delve deeper into the issue under discussion, or move on to another aspect of the same issue.</p>

<p>At some point, you will pause the discussion again, as explained before, and we will continue the same process until I am satisfied with the solution.</p>]]></content><author><name>lina</name></author><category term="speculation" /><category term="AI projects" /><category term="projects/idea" /><category term="bioart" /><category term="bio-things" /><category term="arduino" /><category term="motor" /><category term="insects" /><summary type="html"><![CDATA[Introduction]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://live.staticflickr.com/65535/53872023992_1f152e5801_z.jpg" /><media:content medium="image" url="https://live.staticflickr.com/65535/53872023992_1f152e5801_z.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Bananas, The Surprising Significance of the Ordinary</title><link href="https://blog.lilothink.science/bananas-the-surprising-significance-of-the-ordinary/" rel="alternate" type="text/html" title="Bananas, The Surprising Significance of the Ordinary" /><published>2024-07-20T00:00:00+00:00</published><updated>2024-07-20T00:00:00+00:00</updated><id>https://blog.lilothink.science/bananas-the-surprising-significance-of-the-ordinary</id><content type="html" xml:base="https://blog.lilothink.science/bananas-the-surprising-significance-of-the-ordinary/"><![CDATA[<p>I recently had an incredibly stimulating conversation with a curator. At one point, he drew my attention to the strange power that ordinary things can possess. “The displacement of the ordinary” was the theme of his provocation. Perhaps one of these displacements occurred immediately afterward (certainly as a consequence of the conversation that had just ended) when I went to grab a banana to eat and encountered something unexpected.</p>

<p>It may be hard to recall a living being more mundanely present (yet only perceived to the extent that its profoundly ordinary nature is reinforced) than the small fruit flies. These diminutive insects, from the genus Drosophila, have such subtle traits that they escape the uninterested eye. This eye, annoyed, merely acknowledges their presence in the fruit bowl, hovering over the fruits, especially bananas.</p>

<p>What few people know (and understandably so, as the following is niche knowledge that one wouldn’t expect from those who merely want to eat their banana) is that this insignificant creature has had an enormous instrumental importance for the development of genetics. Much of what we know today about heredity, reproduction, chromosomes, and genes stems from elaborate experiments conducted with these tiny flies. Born in glass bottles and induced to mate with other flies, different from them in some identifiable way, scientists meticulously analyzed their offspring in search of the laws governing inherited traits.</p>

<p>It was while pondering this ordinary organism that I almost forgot to bite into my banana.</p>

<p><img src="https://live.staticflickr.com/65535/53868560126_4e67a8fec4_z.jpg" /></p>

<p><em>From The North American Species of Drosophila by Alfred H. Sturtevant, with drawings by Edith M. Wallace., published in 1921 by the Carnegie Institution of Washington (now the Carnegie Institution for Science).</em></p>]]></content><author><name>eduardo</name></author><category term="speculation" /><category term="bio-art" /><category term="creative-process" /><category term="bio-things" /><category term="insects" /><category term="food" /><summary type="html"><![CDATA[I recently had an incredibly stimulating conversation with a curator. At one point, he drew my attention to the strange power that ordinary things can possess. “The displacement of the ordinary” was the theme of his provocation. Perhaps one of these displacements occurred immediately afterward (certainly as a consequence of the conversation that had just ended) when I went to grab a banana to eat and encountered something unexpected.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://live.staticflickr.com/65535/53868560126_4e67a8fec4_z.jpg" /><media:content medium="image" url="https://live.staticflickr.com/65535/53868560126_4e67a8fec4_z.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">What Challenges Lie Ahead in 3D Food Printing? My First Prototype Sprint in Switzerland</title><link href="https://blog.lilothink.science/what-challenges-lie-ahead-in-3d-food-printing-my-first-prototype-sprint-in-switzerland/" rel="alternate" type="text/html" title="What Challenges Lie Ahead in 3D Food Printing? My First Prototype Sprint in Switzerland" /><published>2024-07-17T00:00:00+00:00</published><updated>2024-07-17T00:00:00+00:00</updated><id>https://blog.lilothink.science/what-challenges-lie-ahead-in-3d-food-printing-my-first-prototype-sprint-in-switzerland</id><content type="html" xml:base="https://blog.lilothink.science/what-challenges-lie-ahead-in-3d-food-printing-my-first-prototype-sprint-in-switzerland/"><![CDATA[<p><em>This prototype is a partnership with my amazing husband and friend Fadri Pestalozzi 🫀</em></p>

<h2 id="challenges-of-food-printing-at-home">Challenges of Food Printing (at home)</h2>

<p>Embarking on the fascinating journey of developing a 3D bioprinter at home, my focus is on culinary applications rather than the more conventional uses in healthcare or biomaterials. While 3D bioprinting technology often involves working with human cells for medical purposes or creating hydrogels, biocomposites, and bioplastics, my compact home studio steers me towards an innovative yet practical niche: <strong>food printing</strong>.</p>

<p>Although many associate food 3D printing with sweet treats like chocolate or sugar due to their ease of manipulation when heated, my interest lies in crafting savory dishes. This venture poses unique challenges but also promises exciting possibilities. In this blog post, I will share my initial experiences in developing a printhead designed specifically for creating savory foods, exploring the potential and intricacies of this cutting-edge culinary technology.</p>

<p>My journey into 3D food printing began with a robust metal framework, presenting the challenge of developing a printhead capable of handling pasty or gelled foods rather than plastics. This research quest started back in 2019 with the help of Janaína and Leandro from BioEdTech, who designed the initial printhead that we adapted to include a syringe. You can check the experience in this other post.</p>

<h2 id="what-do-food-and-ceramics-have-in-common">What do food and ceramics have in common?</h2>

<p>While this small syringe was perfect for medical applications, such as printing cells or bacteria, it proved inadequate for my culinary ambitions. Food, especially in Brazilian culture, means abundance, and I needed a printhead that could handle larger quantities. This need led me to explore 3D ceramic printers… what?!?!</p>

<p>3D ceramic printers face similar challenges to food printers, handling large volumes of pasty materials that must be air-bubble-free to avoid deformation. I discovered a fascinating project by Polish ceramic artist <a href="https://www.instagram.com/piotr_wasniowski/">Piotr Waśniowski</a> , who uses a compressed air system and a helical extruder to keep the material bubble-free.</p>

<p>The most exciting part? His printhead uses cake decorating tips with varying cone-shaped diameters, perfect for preventing material shear during printing. This discovery inspired my own adaptation: a printhead that ensures a homogenous, air-free food material for my culinary creations.</p>

<p>I am grateful for Piotr Waśniowski’s open innovation approach. He developed this printhead for his ceramic work and shared it as open-source on <a href="https://www.thingiverse.com/thing:4805607">Thingiverse</a>, allowing others to use, modify, and test their own versions. I am a strong advocate for open innovation and thorough documentation.</p>

<p>So, let’s go! Piotr’s design features a large cartridge for material feeding and compressed air pumping, with a motor driving the helical extruder. This versatile design can be adapted for various 3D printers, making it an excellent starting point. In prototyping, I’ve learned the value of quick, iterative testing—building a rapid, “dirty” prototype to understand volumes and functionality. I printed Piotr’s design as-is to get a tangible feel and learn through hands-on experience.</p>

<hr />

<h2 id="pause-for-personal-reflection">Pause for personal reflection</h2>

<p>One of the highlights of this project was what felt like my first experience with a true sprint in Switzerland. On a Wednesday morning, we listed the materials we needed, checked what we had in the home studio, and set out to acquire the rest from local shops—a bike store and a construction supply store.</p>

<p>By the end of the day, after some improvisation, like drilling a larger hole for a thicker tube, we had a rough prototype in our hands. This was a personal milestone for me, demonstrating my ability to execute an agile project in my new context of living in Switzerland, where access to materials and tools differs significantly from São Paulo.</p>

<p>It was a reaffirmation that I can adapt and still achieve quick, tangible results, gaining a deeper understanding of the local culture and resources. This experience was a personal victory, marking a successful day where I ended with a working prototype and a renewed sense of capability.</p>

<p><img src="https://live.staticflickr.com/65535/53864788613_a861fe8f7c_b.jpg" /></p>

<hr />

<h2 id="future-directions-and-adaptations">Future Directions and Adaptations</h2>

<p>From our current setup, I’ve learned that we’ll need to modify the attachment axis between the printhead and the printer’s X-axis. The weight of the printhead, loaded with material, creates a lever effect, so we’ll adapt the structure to metal and secure it with screws. Given that we’re working with food and various recipes, the ideal solution is a detachable system for easy cleaning.</p>

<p>I plan to create two pieces: one for attaching to the X-axis and another for the removable printhead, ensuring it’s easy to wash. This involves considering the electronics and designing an interchangeable system, accommodating future heads for different materials like bacteria or human cells.</p>

<p>This design challenge is exciting because it allows for versatile use—whether for food, biomaterials, or cells—while maintaining a hygienic and easily cleanable setup. Ultimately, <strong>I’ll design a robust engagement system that supports easy cleaning and adaptability for different purposes, aiming for a future-proof, versatile printer</strong>.</p>

<p><a data-flickr-embed="true" href="https://www.flickr.com/photos/200845412@N02/albums/72177720318893186" title="2024 BioPrinter Head"><img src="https://live.staticflickr.com/65535/53863693632_162e526e8c_c.jpg" alt="2024 BioPrinter Head" /></a><script async="" src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script></p>

<p><em>Clique on the image to see the gallery on Flickr</em></p>]]></content><author><name>lina</name></author><category term="documentation" /><category term="sprint" /><category term="Bio3D printing" /><category term="bio3dprusa" /><category term="prototype" /><category term="food" /><summary type="html"><![CDATA[This prototype is a partnership with my amazing husband and friend Fadri Pestalozzi 🫀]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://live.staticflickr.com/65535/53863693632_162e526e8c_b.jpg" /><media:content medium="image" url="https://live.staticflickr.com/65535/53863693632_162e526e8c_b.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Palavras em Jogo - Como os Vídeos do YouTube Influenciam o Vocabulário das Crianças?</title><link href="https://blog.lilothink.science/palavras-em-jogo-como-os-videos-do-youtube-influenciam-o-vocabulario-das-criancas/" rel="alternate" type="text/html" title="Palavras em Jogo - Como os Vídeos do YouTube Influenciam o Vocabulário das Crianças?" /><published>2024-07-13T00:00:00+00:00</published><updated>2024-07-13T00:00:00+00:00</updated><id>https://blog.lilothink.science/palavras-em-jogo-como-os-videos-do-youtube-influenciam-o-vocabulario-das-criancas</id><content type="html" xml:base="https://blog.lilothink.science/palavras-em-jogo-como-os-videos-do-youtube-influenciam-o-vocabulario-das-criancas/"><![CDATA[<h2 id="a-influência-dos-vídeos-no-vocabulário-infantil">A Influência dos Vídeos no Vocabulário Infantil</h2>

<p>O gatilho para esta análise veio de um comentário da professora Recy Freire, que tem notado uma preocupante tendência entre seus alunos de 7 a 10 anos. Ela percebe que muitas crianças apresentam dificuldades com ortografia, possuem um vocabulário reduzido e enfrentam desafios na interpretação de texto. Recy acredita firmemente que a leitura é essencial para a aquisição de vocabulário e para a melhoria da capacidade de interpretação de texto.</p>

<p>No entanto, ela observa que essas crianças parecem não estar desenvolvendo o hábito de leitura, possivelmente por falta de incentivo em casa. Embora Recy não tenha nada contra a tecnologia ou o uso de telas – compreendendo que muitas vezes os pais recorrem aos tablets para ganhar tempo –, ela sente que essa geração está ficando carente em termos de expressão verbal e escrita. Ela relaciona essa carência ao tempo excessivo que as crianças passam assistindo vídeos no YouTube e consumindo conteúdo rápido e produzido para as redes sociais.</p>

<h2 id="o-valor-da-linguagem-e-a-crítica-ao-elitismo-linguístico">O Valor da Linguagem e a Crítica ao Elitismo Linguístico</h2>

<p>Paralelamente às inquietações de Recy, surge uma reflexão sobre o valor que atribuímos à ortografia, ao vocabulário e à leitura, e se essa valorização não carrega um viés elitista. O filologista brasileiro Marcos Bagno, autor de obras como “A Língua de Eulália” e “O Preconceito Linguístico”, nos convida a reconsiderar esses julgamentos.</p>

<p>Minha própria experiência pessoal reflete essa questão: minha avó, que se alfabetizou aos 40 anos, tinha um vocabulário mais simples e um sistema gramatical mais básico devido à falta de acesso à escolarização formal. No entanto, a ausência de estudo não desqualificava suas palavras nem sua experiência de vida.</p>

<p>Será que, ao valorizar excessivamente a leitura e a escrita formal, não estamos caindo no preconceito linguístico apontado por Bagno? Ao escrevermos sobre a infância e o desenvolvimento linguístico, como no caso do livro “A Infância de Gepeto”, corremos o risco de adotar uma perspectiva elitista que desvaloriza outras formas legítimas de expressão e conhecimento.</p>

<h2 id="o-processo">O Processo</h2>

<p>Refletindo sobre todas essas questões, decidi perguntar à minha filha, Diana, de 10 anos, quais são os canais do YouTube que ela mais assiste. Ela me forneceu uma lista com cinco canais, e eu decidi analisar os dois vídeos mais recentes de cada um desses canais. Embora um dos canais seja em inglês, traduzi o conteúdo para o português para manter a consistência da análise.</p>

<p>Notei que a duração dos vídeos variava, com alguns tendo seis minutos e outros chegando a vinte minutos, mas decidi não me ater a essa diferença, já que meu objetivo era fazer uma análise inicial do vocabulário usado. A pergunta que me guiou foi: o que esses dez vídeos do YouTube revelam sobre o vocabulário que as crianças estão absorvendo?</p>

<p>Não procuro respostas definitivas, mas sim explorar e entender melhor a influência desses conteúdos, sempre lembrando que cada criador está fazendo o melhor dentro de suas possibilidades. Essa análise é um convite para um diálogo mais amplo sobre como nossas crianças estão desenvolvendo suas habilidades linguísticas e de compreensão de texto.</p>

<p>Para realizar essa análise de vocabulário, fui ao YouTube e baixei a transcrição desses dez vídeos. Em seguida, utilizei as ferramentas da OpenAI e do ChatGPT para listar as 500 palavras mais usadas, focando em substantivos, adjetivos, verbos e advérbios, excluindo preposições, artigos e conectores.</p>

<p>Com essas transcrições em mãos, pedi para gerar um documento que contivesse as 500 palavras mais usadas em cada vídeo. Depois de obter essas dez listas, solicitei uma análise adicional para identificar as 500 palavras mais comuns entre os dez vídeos. Esse processo em duas camadas resultou em um arquivo final, destacando essas palavras mais frequentes.</p>

<p>Para visualizar os resultados, criei uma nuvem de palavras. Esse exercício levanta várias questões: O vocabulário dos vídeos reflete o que consideramos adequado para o desenvolvimento linguístico das crianças? Como essas palavras se comparam ao vocabulário adquirido através da leitura? E, mais importante, o que essa análise nos revela sobre as influências modernas no aprendizado das nossas crianças?</p>

<p><img src="https://live.staticflickr.com/65535/53863801335_2cc8b174f8_b.jpg" alt="Nuvem de Palavras" /></p>

<p>Durante essa análise, lembrei que não considerei vídeos de tamanhos uniformes e não limpei a base na primeira iteração, o que resultou em possíveis duplicidades como “São Paulo” se transformando em “São” e “Paulo”. Essa análise foi mais um rascunho, um esboço inicial para identificar as palavras mais recorrentes. Não excluí pronomes, pois muitos vídeos de YouTube são narrados em primeira pessoa, o que justifica a presença frequente de pronomes como “eu”.</p>

<p>Com as 500 palavras em mãos, pedi ao ChatGPT para reescrever um trecho de “Dom Casmurro”, meu livro favorito de Machado de Assis, utilizando esse vocabulário. A escolha do livro foi puramente pessoal, sem nenhuma razão específica além da minha admiração por Machado de Assis.</p>

<p>O resultado foi um texto que, apesar de inspirado em um autor tão eloquente, apresentou um vocabulário relativamente limitado, refletindo as palavras mais usadas nos vídeos analisados. Esse exercício não apenas ilustra o vocabulário presente no conteúdo que as crianças consomem, mas também levanta questões sobre o impacto desse vocabulário em seu desenvolvimento linguístico.</p>

<hr />

<h2 id="o-texto">O Texto</h2>

<p>Memórias Adaptadas de Brás Cubas
Capítulo I: Início</p>

<p>Eu, Brás Cubas, escrevo esta memória. Eu falo de minha vida aqui. Muito aqui para contar. Eu sou feliz? Não sei.</p>

<p>Capítulo II: Infância</p>

<p>Minha infância foi boa. Minha mãe era amor. Meu pai, severo. Nós, crianças, brincávamos muito. Mas também aprendíamos. Escola, casa, escola. Um ciclo.</p>

<p>Capítulo III: Amor</p>

<p>Eu vi Marcela. Linda, doce. Eu amei Marcela. Mas ela não. Marcela amava riqueza. Eu, um tolo.</p>

<p>Capítulo IV: Vida Adulta</p>

<p>Vida passou. Trabalho, amigos, festas. Muitos momentos bons. Alguns, nem tanto. Buscava algo. Nunca achei.</p>

<p>Capítulo V: Fim</p>

<p>Agora, escrevo do além. Reflito sobre tudo. Vida é breve. Muito breve. Memórias, só memórias. E nada mais.</p>

<hr />

<h2 id="imaginações-limitadas-e-a-importância-das-palavras">Imaginações Limitadas e a Importância das Palavras</h2>

<p>O comentário da Recy revela um receio profundo: a redução do vocabulário e a chamada “burrificação da língua” podem levar a uma estratégia de governança, onde um grupo de pessoas com vocabulário limitado se torna mais fácil de controlar, perdendo sua capacidade crítica por falta das ferramentas necessárias – as palavras. Ela chama isso de idiotização, uma transformação que empobrece o pensamento.</p>

<p>Para mim, essa redução impacta diretamente a imaginação. Quando lemos ficção científica, por exemplo, somos apresentados a palavras para coisas que ainda não existem, porque a língua é viva e essencial para a criação. A língua falada difere da escrita, mas ambas são cruciais para expandir nossos horizontes.</p>

<p>Como disse Guimarães Rosa, “se existe a palavra, existe a coisa”. Expandir nosso vocabulário é, portanto, ampliar nossa imaginação, criar novas metáforas cognitivas e enriquecer nossa capacidade de expressão. Insistir na expansão do vocabulário é insistir no poder de criação e na possibilidade infinita de novas ideias. É através das palavras que podemos não apenas descrever o mundo, mas também sonhá-lo e transformá-lo.</p>]]></content><author><name>lina</name></author><category term="speculation" /><category term="documentation" /><category term="portuguese" /><category term="writing" /><category term="IG" /><category term="for-kids" /><category term="youtube" /><summary type="html"><![CDATA[A Influência dos Vídeos no Vocabulário Infantil]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://live.staticflickr.com/65535/53863801335_2cc8b174f8_b.jpg" /><media:content medium="image" url="https://live.staticflickr.com/65535/53863801335_2cc8b174f8_b.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Building Your Online Portfolio: A Beginner’s Guide to Jekyll and GitHub Pages</title><link href="https://blog.lilothink.science/building-your-online-portfolio-a-beginner-s-guide-to-jekyll-and-github-pages/" rel="alternate" type="text/html" title="Building Your Online Portfolio: A Beginner’s Guide to Jekyll and GitHub Pages" /><published>2024-07-10T00:00:00+00:00</published><updated>2024-07-10T00:00:00+00:00</updated><id>https://blog.lilothink.science/building-your-online-portfolio-a-beginner-s-guide-to-jekyll-and-github-pages</id><content type="html" xml:base="https://blog.lilothink.science/building-your-online-portfolio-a-beginner-s-guide-to-jekyll-and-github-pages/"><![CDATA[<p>In today’s digital age, having an online portfolio is essential for showcasing your work and attracting potential clients or employers. This tutorial will guide you through creating and hosting a stylish, responsive portfolio using Jekyll and GitHub Pages. Jekyll is a simple, blog-aware static site generator that’s perfect for creating personal sites and portfolios. GitHub Pages offers a free, easy way to host your static websites directly from a GitHub repository.</p>

<p>Ready to get started? Let’s dive in!</p>

<hr />

<h2 id="step-1-installing-jekyll-on-your-machine">Step 1: Installing Jekyll on Your Machine</h2>
<h3 id="what-youll-need">What You’ll Need</h3>

<ul>
  <li>A terminal (command line interface)</li>
  <li>Ruby (the programming language Jekyll is built on)</li>
</ul>

<h3 id="step-by-step">Step-by-step</h3>
<ol>
  <li>
    <p><strong>Check for Ruby Installation:</strong> 
 Open your terminal and type:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> ruby -v 
</code></pre></div>    </div>

    <p>If Ruby isn’t installed, you’ll need to install it. For macOS, you can use Homebrew:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> brew install ruby 
</code></pre></div>    </div>

    <p>For Windows, use RubyInstaller: <a href="https://rubyinstaller.org/">Download RubyInstaller</a></p>
  </li>
  <li>
    <p><strong>Install Jekyll and Bundler:</strong> 
 With Ruby installed, you can now install Jekyll and Bundler gems:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> gem install jekyll bundler 
</code></pre></div>    </div>
  </li>
</ol>

<h2 id="step-2-setting-up-your-jekyll-portfolio">Step 2: Setting Up Your Jekyll Portfolio</h2>
<h4 id="creating-a-new-jekyll-site">Creating a New Jekyll Site</h4>
<ol>
  <li>
    <p><strong>Create a new Jekyll site:</strong></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> jekyll new my-portfolio <span class="nb">cd </span>my-portfolio
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Install Dependencies:</strong></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> bundle <span class="nb">install</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Run Your Site Locally:</strong></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> bundle <span class="nb">exec </span>jekyll serve
</code></pre></div>    </div>

    <p>Open <code class="language-plaintext highlighter-rouge">http://localhost:4000</code> in your browser to see your site.</p>
  </li>
</ol>

<h4 id="configuring-your-portfolio">Configuring Your Portfolio</h4>
<ol>
  <li>
    <p><strong>Markdown:</strong> Use Markdown to write your content. Create a new file in the <code class="language-plaintext highlighter-rouge">_posts</code> directory with the following format:</p>

    <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">  ---</span>
  layout: post title: "My First Project" 
  date: YYYY-MM-DD 
<span class="p">  ---
	 </span>
  ## Project Title 
  Description of your project. 
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Structure:</strong></p>
    <ul>
      <li><strong>_layouts:</strong> Templates for your pages (e.g., default.html).</li>
      <li><strong>_pages:</strong> Individual pages (e.g., about.md).</li>
      <li><strong>_posts:</strong> Blog posts or project entries.</li>
      <li><strong>_config.yml:</strong> Your site’s configuration file.</li>
    </ul>
  </li>
</ol>

<h3 id="step-3-creating-a-github-account-and-repository">Step 3: Creating a GitHub Account and Repository</h3>

<ol>
  <li><strong>Create a GitHub Account:</strong> 
 If you don’t have one, sign up at <a href="https://github.com/">GitHub</a>.</li>
  <li><strong>Create a New Repository:</strong>
    <ul>
      <li>Click on the “New” button on your GitHub dashboard.</li>
      <li>Name your repository <code class="language-plaintext highlighter-rouge">&lt;your-username&gt;.github.io</code>.</li>
      <li>Initialize with a README file.</li>
    </ul>
  </li>
</ol>

<h3 id="step-4-hosting-your-portfolio-on-github-pages">Step 4: Hosting Your Portfolio on GitHub Pages</h3>

<ol>
  <li>
    <p><strong>Push Your Site to GitHub:</strong></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> git init 
 git add <span class="nb">.</span> 
 git commit <span class="nt">-m</span> <span class="s2">"Initial commit"</span> 
 git remote add origin https://github.com/&lt;your-username&gt;/&lt;your-repo&gt;.git 
 git branch <span class="nt">-M</span> main 
 git push <span class="nt">-u</span> origin main 
</code></pre></div>    </div>
  </li>
  <li><strong>Enable GitHub Pages:</strong>
    <ul>
      <li>Go to your repository’s settings.</li>
      <li>Scroll down to the “GitHub Pages” section.</li>
      <li>Under “Source,” select the <code class="language-plaintext highlighter-rouge">main</code> branch and click “Save.”</li>
    </ul>
  </li>
  <li><strong>Visit Your Site:</strong> Your portfolio will be live at <code class="language-plaintext highlighter-rouge">https://&lt;your-username&gt;.github.io/</code>.</li>
</ol>

<h1>*</h1>

<h3 id="bonus-tips">Bonus Tips:</h3>

<ul>
  <li><strong>Custom Domain:</strong> You can set up a custom domain for your GitHub Pages site in the repository settings.</li>
  <li><strong>Themes:</strong> Explore and apply different Jekyll themes to give your portfolio a unique look.</li>
  <li><strong>Plugins:</strong> Enhance your site’s functionality with Jekyll plugins.</li>
</ul>

<p>For those of you who love to dive deeper and explore all the nifty details, check out the official Jekyll installation guide and the <a href="https://docs.github.com/en/pages/getting-started-with-github-pages">GitHub Pages configuration page</a>. These resources are packed with tips, tricks, and advanced features to make your portfolio truly shine.</p>

<p>Happy coding, and happy exploring! 🚀✨</p>]]></content><author><name>lina</name></author><category term="documentation" /><category term="digital tools" /><category term="tutorial" /><category term="Jekyll" /><category term="github" /><summary type="html"><![CDATA[In today’s digital age, having an online portfolio is essential for showcasing your work and attracting potential clients or employers. This tutorial will guide you through creating and hosting a stylish, responsive portfolio using Jekyll and GitHub Pages. Jekyll is a simple, blog-aware static site generator that’s perfect for creating personal sites and portfolios. GitHub Pages offers a free, easy way to host your static websites directly from a GitHub repository.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://live.staticflickr.com/65535/53848757363_f2a44ba3e7_b.jpg" /><media:content medium="image" url="https://live.staticflickr.com/65535/53848757363_f2a44ba3e7_b.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>